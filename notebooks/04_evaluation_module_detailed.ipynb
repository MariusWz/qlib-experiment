{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Backtesting, Evaluation and Portfolio Analysis\n",
    "# ç¬¬å››ç« ï¼šå›æµ‹ã€è¯„ä¼°ä¸ç»„åˆåˆ†æ\n",
    "\n",
    "**Author**: Microsoft Qlib Team  \n",
    "**License**: MIT License  \n",
    "**Last Updated**: 2025-01-09\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š Table of Contents / ç›®å½•\n",
    "\n",
    "1. [Evaluation Framework Overview / è¯„ä¼°æ¡†æ¶æ¦‚è§ˆ](#evaluation-framework)\n",
    "2. [Backtesting Infrastructure / å›æµ‹åŸºç¡€è®¾æ–½](#backtesting)\n",
    "3. [Trading Strategies / äº¤æ˜“ç­–ç•¥](#strategies)\n",
    "   - 3.1 [Top-K Strategy](#topk-strategy)\n",
    "   - 3.2 [Signal-based Strategies](#signal-strategies)\n",
    "   - 3.3 [Custom Strategies](#custom-strategies)\n",
    "4. [Execution and Order Management / æ‰§è¡Œä¸è®¢å•ç®¡ç†](#execution)\n",
    "5. [Portfolio Analysis / ç»„åˆåˆ†æ](#portfolio-analysis)\n",
    "6. [Risk Metrics / é£é™©æŒ‡æ ‡](#risk-metrics)\n",
    "7. [Performance Attribution / ä¸šç»©å½’å› ](#attribution)\n",
    "8. [Signal Analysis / ä¿¡å·åˆ†æ](#signal-analysis)\n",
    "9. [Transaction Cost Analysis / äº¤æ˜“æˆæœ¬åˆ†æ](#tca)\n",
    "10. [Visualization and Reporting / å¯è§†åŒ–ä¸æŠ¥å‘Š](#visualization)\n",
    "11. [Advanced Evaluation Techniques / é«˜çº§è¯„ä¼°æŠ€æœ¯](#advanced)\n",
    "12. [Production Monitoring / ç”Ÿäº§ç›‘æ§](#monitoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports / è®¾ç½®å’Œå¯¼å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports / å¿…è¦å¯¼å…¥\n",
    "import qlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from datetime import datetime, timedelta\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Qlib specific imports / Qlibç‰¹å®šå¯¼å…¥\n",
    "from qlib.data import D\n",
    "from qlib.config import C\n",
    "from qlib.workflow import R\n",
    "from qlib.workflow.record_temp import SignalRecord, PortAnaRecord, SigAnaRecord\n",
    "from qlib.utils import init_instance_by_config\n",
    "\n",
    "# Backtesting imports / å›æµ‹å¯¼å…¥\n",
    "from qlib.backtest import backtest\n",
    "from qlib.backtest.executor import SimulatorExecutor\n",
    "from qlib.backtest.exchange import Exchange\n",
    "from qlib.backtest.account import Account\n",
    "\n",
    "# Strategy imports / ç­–ç•¥å¯¼å…¥\n",
    "from qlib.contrib.strategy.signal_strategy import TopkDropoutStrategy\n",
    "from qlib.contrib.evaluate import risk_analysis\n",
    "from qlib.contrib.report import analysis_position, analysis_model\n",
    "\n",
    "# Visualization settings / å¯è§†åŒ–è®¾ç½®\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Qlib and load configuration / åˆå§‹åŒ–Qlibå¹¶åŠ è½½é…ç½®\n",
    "qlib.init()\n",
    "\n",
    "# Load experiment configuration / åŠ è½½å®éªŒé…ç½®\n",
    "try:\n",
    "    with open('experiment_config.json', 'r') as f:\n",
    "        exp_config = json.load(f)\n",
    "    print(\"âœ… Experiment configuration loaded\")\n",
    "except FileNotFoundError:\n",
    "    exp_config = {\n",
    "        \"market\": \"csi300\",\n",
    "        \"benchmark\": \"SH000300\",\n",
    "        \"exp_name\": \"evaluation_exp\",\n",
    "        \"train_start\": \"2008-01-01\",\n",
    "        \"train_end\": \"2014-12-31\",\n",
    "        \"valid_start\": \"2015-01-01\",\n",
    "        \"valid_end\": \"2016-12-31\",\n",
    "        \"test_start\": \"2017-01-01\",\n",
    "        \"test_end\": \"2020-08-01\"\n",
    "    }\n",
    "    print(\"âš ï¸ Using default configuration\")\n",
    "\n",
    "# Load saved model and predictions / åŠ è½½ä¿å­˜çš„æ¨¡å‹å’Œé¢„æµ‹\n",
    "try:\n",
    "    model_dir = Path('saved_models')\n",
    "    with open(model_dir / 'predictions.pkl', 'rb') as f:\n",
    "        predictions = pickle.load(f)\n",
    "    print(\"âœ… Predictions loaded\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âš ï¸ No saved predictions found. Generating sample predictions...\")\n",
    "    # Generate sample predictions for demonstration\n",
    "    dates = pd.date_range(exp_config['test_start'], exp_config['test_end'], freq='D')\n",
    "    instruments = D.instruments(exp_config['market'])[:50]\n",
    "    index = pd.MultiIndex.from_product([dates, instruments], names=['datetime', 'instrument'])\n",
    "    predictions = pd.Series(np.random.randn(len(index)) * 0.01, index=index, name='score')\n",
    "\n",
    "print(f\"\\nExperiment: {exp_config['exp_name']}\")\n",
    "print(f\"Test period: {exp_config['test_start']} to {exp_config['test_end']}\")\n",
    "print(f\"Predictions shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Evaluation Framework Overview / è¯„ä¼°æ¡†æ¶æ¦‚è§ˆ <a id='evaluation-framework'></a>\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    Qlib Evaluation Framework                         â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                       â”‚\n",
    "â”‚     Model Predictions                                                â”‚\n",
    "â”‚            â†“                                                         â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚\n",
    "â”‚   â”‚ Signal Analysis â”‚ â† IC, Rank IC, Auto-correlation              â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚\n",
    "â”‚            â†“                                                         â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚\n",
    "â”‚   â”‚    Strategy     â”‚ â† Top-K, Dropout, Signal-based              â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚\n",
    "â”‚            â†“                                                         â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚\n",
    "â”‚   â”‚    Executor     â”‚ â† Order generation, Position management      â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚\n",
    "â”‚            â†“                                                         â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚\n",
    "â”‚   â”‚    Exchange     â”‚ â† Trade execution, Cost calculation         â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚\n",
    "â”‚            â†“                                                         â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚\n",
    "â”‚   â”‚     Performance Analysis            â”‚                         â”‚\n",
    "â”‚   â”‚  â€¢ Returns & Risk Metrics           â”‚                         â”‚\n",
    "â”‚   â”‚  â€¢ Portfolio Analytics              â”‚                         â”‚\n",
    "â”‚   â”‚  â€¢ Attribution Analysis             â”‚                         â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Backtesting Infrastructure / å›æµ‹åŸºç¡€è®¾æ–½ <a id='backtesting'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic backtesting configuration / åŸºç¡€å›æµ‹é…ç½®\n",
    "\n",
    "backtest_config = {\n",
    "    \"start_time\": exp_config['test_start'],\n",
    "    \"end_time\": exp_config['test_end'],\n",
    "    \"account\": 10000000,  # Initial capital: 10M / åˆå§‹èµ„é‡‘ï¼š1000ä¸‡\n",
    "    \"benchmark\": exp_config['benchmark'],\n",
    "    \"exchange_kwargs\": {\n",
    "        \"freq\": \"day\",\n",
    "        \"limit_threshold\": 0.095,  # Daily limit 9.5% / æ¶¨è·Œåœé™åˆ¶9.5%\n",
    "        \"deal_price\": \"close\",      # Trade at close price / ä»¥æ”¶ç›˜ä»·æˆäº¤\n",
    "        \"open_cost\": 0.0005,        # Buy cost 0.05% / ä¹°å…¥æˆæœ¬0.05%\n",
    "        \"close_cost\": 0.0015,       # Sell cost 0.15% / å–å‡ºæˆæœ¬0.15%\n",
    "        \"min_cost\": 5,              # Minimum cost 5 yuan / æœ€ä½æ‰‹ç»­è´¹5å…ƒ\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"Backtest Configuration / å›æµ‹é…ç½®:\")\n",
    "print(\"=\"*50)\n",
    "for key, value in backtest_config.items():\n",
    "    if key != \"exchange_kwargs\":\n",
    "        print(f\"{key:15}: {value}\")\n",
    "\n",
    "print(\"\\nExchange Settings / äº¤æ˜“æ‰€è®¾ç½®:\")\n",
    "for key, value in backtest_config[\"exchange_kwargs\"].items():\n",
    "    print(f\"  {key:15}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create exchange and account / åˆ›å»ºäº¤æ˜“æ‰€å’Œè´¦æˆ·\n",
    "\n",
    "from qlib.backtest import Exchange, Account\n",
    "\n",
    "# Initialize exchange / åˆå§‹åŒ–äº¤æ˜“æ‰€\n",
    "exchange = Exchange(\n",
    "    trade_dates=D.calendar(start_time=backtest_config['start_time'], \n",
    "                          end_time=backtest_config['end_time']),\n",
    "    **backtest_config['exchange_kwargs']\n",
    ")\n",
    "\n",
    "# Initialize account / åˆå§‹åŒ–è´¦æˆ·\n",
    "account = Account(init_cash=backtest_config['account'])\n",
    "\n",
    "print(f\"Exchange initialized with {len(exchange.trade_dates)} trading days\")\n",
    "print(f\"Account initialized with ${backtest_config['account']:,.0f} capital\")\n",
    "\n",
    "# Display trading calendar sample / æ˜¾ç¤ºäº¤æ˜“æ—¥å†æ ·ä¾‹\n",
    "print(f\"\\nFirst 5 trading days: {exchange.trade_dates[:5].tolist()}\")\n",
    "print(f\"Last 5 trading days: {exchange.trade_dates[-5:].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Trading Strategies / äº¤æ˜“ç­–ç•¥ <a id='strategies'></a>\n",
    "\n",
    "### 3.1 Top-K Strategy <a id='topk-strategy'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-K Dropout Strategy Implementation / Top-K Dropoutç­–ç•¥å®ç°\n",
    "\n",
    "from qlib.contrib.strategy.signal_strategy import TopkDropoutStrategy\n",
    "\n",
    "# Strategy configuration / ç­–ç•¥é…ç½®\n",
    "topk_strategy_config = {\n",
    "    \"signal\": predictions,           # Model predictions / æ¨¡å‹é¢„æµ‹\n",
    "    \"topk\": 50,                     # Select top 50 stocks / é€‰æ‹©å‰50åªè‚¡ç¥¨\n",
    "    \"n_drop\": 5,                    # Drop worst 5 each period / æ¯æœŸæ·˜æ±°æœ€å·®çš„5åª\n",
    "    \"method\": \"top\",                # Selection method / é€‰æ‹©æ–¹æ³•\n",
    "    \"risk_degree\": 0.95,            # Risk control parameter / é£é™©æ§åˆ¶å‚æ•°\n",
    "    \"hold_thresh\": 0,               # Holding threshold / æŒæœ‰é˜ˆå€¼\n",
    "    \"only_tradable\": True,          # Only trade tradable stocks / ä»…äº¤æ˜“å¯äº¤æ˜“è‚¡ç¥¨\n",
    "}\n",
    "\n",
    "# Create strategy instance / åˆ›å»ºç­–ç•¥å®ä¾‹\n",
    "topk_strategy = TopkDropoutStrategy(**topk_strategy_config)\n",
    "\n",
    "print(\"Top-K Dropout Strategy Configuration:\")\n",
    "print(f\"  Top K: {topk_strategy_config['topk']}\")\n",
    "print(f\"  Dropout: {topk_strategy_config['n_drop']}\")\n",
    "print(f\"  Risk degree: {topk_strategy_config['risk_degree']}\")\n",
    "print(f\"  Method: {topk_strategy_config['method']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run backtest with Top-K strategy / è¿è¡ŒTop-Kç­–ç•¥å›æµ‹\n",
    "\n",
    "from qlib.backtest import backtest\n",
    "from qlib.backtest.executor import SimulatorExecutor\n",
    "\n",
    "# Create executor / åˆ›å»ºæ‰§è¡Œå™¨\n",
    "executor = SimulatorExecutor(\n",
    "    time_per_step=\"day\",\n",
    "    generate_portfolio_metrics=True\n",
    ")\n",
    "\n",
    "# Run backtest / è¿è¡Œå›æµ‹\n",
    "print(\"Running backtest...\")\n",
    "portfolio_metrics, indicator_dict = backtest(\n",
    "    strategy=topk_strategy,\n",
    "    executor=executor,\n",
    "    backtest_config=backtest_config,\n",
    "    account=backtest_config[\"account\"],\n",
    "    benchmark=backtest_config[\"benchmark\"],\n",
    "    exchange_kwargs=backtest_config[\"exchange_kwargs\"],\n",
    "    return_order=True\n",
    ")\n",
    "\n",
    "print(\"âœ… Backtest completed\")\n",
    "print(f\"\\nPortfolio metrics keys: {list(portfolio_metrics.keys())}\")\n",
    "print(f\"Indicator dict keys: {list(indicator_dict.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Signal-based Strategies <a id='signal-strategies'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom signal-based strategy / è‡ªå®šä¹‰ä¿¡å·ç­–ç•¥\n",
    "\n",
    "from qlib.contrib.strategy.signal_strategy import SignalStrategy\n",
    "from qlib.backtest.decision import BaseTradeDecision, Order\n",
    "\n",
    "class MomentumStrategy(SignalStrategy):\n",
    "    \"\"\"Momentum-based trading strategy / åŸºäºåŠ¨é‡çš„äº¤æ˜“ç­–ç•¥\"\"\"\n",
    "    \n",
    "    def __init__(self, signal, momentum_window=20, rebalance_freq=5, **kwargs):\n",
    "        super().__init__(signal=signal, **kwargs)\n",
    "        self.momentum_window = momentum_window\n",
    "        self.rebalance_freq = rebalance_freq\n",
    "        self.trade_count = 0\n",
    "    \n",
    "    def generate_trade_decision(self, execute_result=None):\n",
    "        \"\"\"Generate trading decisions / ç”Ÿæˆäº¤æ˜“å†³ç­–\"\"\"\n",
    "        \n",
    "        # Get current date / è·å–å½“å‰æ—¥æœŸ\n",
    "        current_date = self.trade_calendar.get_trade_date()\n",
    "        \n",
    "        # Check if it's rebalance day / æ£€æŸ¥æ˜¯å¦ä¸ºå†å¹³è¡¡æ—¥\n",
    "        self.trade_count += 1\n",
    "        if self.trade_count % self.rebalance_freq != 0:\n",
    "            return BaseTradeDecision([], current_date)\n",
    "        \n",
    "        # Get current signal / è·å–å½“å‰ä¿¡å·\n",
    "        current_signal = self.signal.loc[current_date] if current_date in self.signal.index else pd.Series()\n",
    "        \n",
    "        if current_signal.empty:\n",
    "            return BaseTradeDecision([], current_date)\n",
    "        \n",
    "        # Select top momentum stocks / é€‰æ‹©åŠ¨é‡æœ€å¼ºçš„è‚¡ç¥¨\n",
    "        top_stocks = current_signal.nlargest(30)\n",
    "        \n",
    "        # Generate orders / ç”Ÿæˆè®¢å•\n",
    "        orders = []\n",
    "        position_per_stock = 1.0 / len(top_stocks) if len(top_stocks) > 0 else 0\n",
    "        \n",
    "        for stock, score in top_stocks.items():\n",
    "            if score > 0:  # Only buy positive momentum / åªä¹°å…¥æ­£åŠ¨é‡\n",
    "                order = Order(\n",
    "                    stock_id=stock,\n",
    "                    amount=position_per_stock,\n",
    "                    direction=Order.BUY,\n",
    "                    start_time=current_date,\n",
    "                    end_time=current_date\n",
    "                )\n",
    "                orders.append(order)\n",
    "        \n",
    "        return BaseTradeDecision(orders, current_date)\n",
    "\n",
    "# Create momentum strategy / åˆ›å»ºåŠ¨é‡ç­–ç•¥\n",
    "momentum_strategy = MomentumStrategy(\n",
    "    signal=predictions,\n",
    "    momentum_window=20,\n",
    "    rebalance_freq=5\n",
    ")\n",
    "\n",
    "print(\"Momentum Strategy created\")\n",
    "print(f\"  Momentum window: 20 days\")\n",
    "print(f\"  Rebalance frequency: Every 5 days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Custom Strategies <a id='custom-strategies'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced custom strategy with risk management / å¸¦é£é™©ç®¡ç†çš„é«˜çº§è‡ªå®šä¹‰ç­–ç•¥\n",
    "\n",
    "class RiskManagedStrategy(SignalStrategy):\n",
    "    \"\"\"Strategy with position sizing and risk management\n",
    "    å¸¦ä»“ä½ç®¡ç†å’Œé£é™©æ§åˆ¶çš„ç­–ç•¥\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, signal, max_position=0.1, stop_loss=0.05, \n",
    "                 volatility_target=0.15, **kwargs):\n",
    "        super().__init__(signal=signal, **kwargs)\n",
    "        self.max_position = max_position      # Maximum position per stock / æ¯åªè‚¡ç¥¨æœ€å¤§ä»“ä½\n",
    "        self.stop_loss = stop_loss            # Stop loss threshold / æ­¢æŸé˜ˆå€¼\n",
    "        self.volatility_target = volatility_target  # Target portfolio volatility / ç›®æ ‡ç»„åˆæ³¢åŠ¨ç‡\n",
    "        self.entry_prices = {}                # Track entry prices / è·Ÿè¸ªå…¥åœºä»·æ ¼\n",
    "        \n",
    "    def calculate_position_size(self, stock, signal_strength, current_volatility):\n",
    "        \"\"\"Calculate position size based on signal and volatility\n",
    "        åŸºäºä¿¡å·å’Œæ³¢åŠ¨ç‡è®¡ç®—ä»“ä½å¤§å°\n",
    "        \"\"\"\n",
    "        \n",
    "        # Base position from signal strength / åŸºäºä¿¡å·å¼ºåº¦çš„åŸºç¡€ä»“ä½\n",
    "        base_position = abs(signal_strength) * self.max_position\n",
    "        \n",
    "        # Adjust for volatility / æ ¹æ®æ³¢åŠ¨ç‡è°ƒæ•´\n",
    "        if current_volatility > 0:\n",
    "            volatility_scalar = self.volatility_target / current_volatility\n",
    "            volatility_scalar = min(volatility_scalar, 2.0)  # Cap at 2x\n",
    "            volatility_scalar = max(volatility_scalar, 0.5)  # Floor at 0.5x\n",
    "        else:\n",
    "            volatility_scalar = 1.0\n",
    "        \n",
    "        # Final position size / æœ€ç»ˆä»“ä½å¤§å°\n",
    "        position_size = base_position * volatility_scalar\n",
    "        position_size = min(position_size, self.max_position)\n",
    "        \n",
    "        return position_size\n",
    "    \n",
    "    def check_stop_loss(self, stock, current_price):\n",
    "        \"\"\"Check if stop loss is triggered / æ£€æŸ¥æ˜¯å¦è§¦å‘æ­¢æŸ\"\"\"\n",
    "        \n",
    "        if stock not in self.entry_prices:\n",
    "            return False\n",
    "        \n",
    "        entry_price = self.entry_prices[stock]\n",
    "        loss = (entry_price - current_price) / entry_price\n",
    "        \n",
    "        return loss > self.stop_loss\n",
    "    \n",
    "    def generate_trade_decision(self, execute_result=None):\n",
    "        \"\"\"Generate risk-managed trading decisions\n",
    "        ç”Ÿæˆé£é™©ç®¡ç†çš„äº¤æ˜“å†³ç­–\n",
    "        \"\"\"\n",
    "        \n",
    "        current_date = self.trade_calendar.get_trade_date()\n",
    "        current_signal = self.signal.loc[current_date] if current_date in self.signal.index else pd.Series()\n",
    "        \n",
    "        if current_signal.empty:\n",
    "            return BaseTradeDecision([], current_date)\n",
    "        \n",
    "        orders = []\n",
    "        \n",
    "        # Get current prices and calculate volatility / è·å–å½“å‰ä»·æ ¼å¹¶è®¡ç®—æ³¢åŠ¨ç‡\n",
    "        # Note: Simplified for demonstration / æ³¨æ„ï¼šä¸ºæ¼”ç¤ºè€Œç®€åŒ–\n",
    "        current_volatility = 0.20  # Placeholder / å ä½ç¬¦\n",
    "        \n",
    "        for stock, signal_value in current_signal.items():\n",
    "            # Calculate position size / è®¡ç®—ä»“ä½å¤§å°\n",
    "            position_size = self.calculate_position_size(\n",
    "                stock, signal_value, current_volatility\n",
    "            )\n",
    "            \n",
    "            # Generate order if position size is significant / å¦‚æœä»“ä½æ˜¾è‘—åˆ™ç”Ÿæˆè®¢å•\n",
    "            if position_size > 0.01:\n",
    "                direction = Order.BUY if signal_value > 0 else Order.SELL\n",
    "                order = Order(\n",
    "                    stock_id=stock,\n",
    "                    amount=position_size,\n",
    "                    direction=direction,\n",
    "                    start_time=current_date,\n",
    "                    end_time=current_date\n",
    "                )\n",
    "                orders.append(order)\n",
    "                \n",
    "                # Track entry price / è·Ÿè¸ªå…¥åœºä»·æ ¼\n",
    "                if direction == Order.BUY:\n",
    "                    self.entry_prices[stock] = 100  # Placeholder price\n",
    "        \n",
    "        return BaseTradeDecision(orders, current_date)\n",
    "\n",
    "# Create risk-managed strategy / åˆ›å»ºé£é™©ç®¡ç†ç­–ç•¥\n",
    "risk_strategy = RiskManagedStrategy(\n",
    "    signal=predictions,\n",
    "    max_position=0.1,\n",
    "    stop_loss=0.05,\n",
    "    volatility_target=0.15\n",
    ")\n",
    "\n",
    "print(\"Risk-Managed Strategy created\")\n",
    "print(f\"  Max position per stock: 10%\")\n",
    "print(f\"  Stop loss: 5%\")\n",
    "print(f\"  Volatility target: 15%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Execution and Order Management / æ‰§è¡Œä¸è®¢å•ç®¡ç† <a id='execution'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom executor with advanced features / å¸¦é«˜çº§åŠŸèƒ½çš„è‡ªå®šä¹‰æ‰§è¡Œå™¨\n",
    "\n",
    "from qlib.backtest.executor import BaseExecutor\n",
    "from qlib.backtest.exchange import Exchange\n",
    "from qlib.backtest.account import Account\n",
    "\n",
    "class AdvancedExecutor(BaseExecutor):\n",
    "    \"\"\"Advanced executor with slippage and market impact modeling\n",
    "    å¸¦æ»‘ç‚¹å’Œå¸‚åœºå†²å‡»å»ºæ¨¡çš„é«˜çº§æ‰§è¡Œå™¨\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, time_per_step=\"day\", slippage_rate=0.001, \n",
    "                 market_impact_model=\"linear\", **kwargs):\n",
    "        super().__init__(time_per_step=time_per_step, **kwargs)\n",
    "        self.slippage_rate = slippage_rate\n",
    "        self.market_impact_model = market_impact_model\n",
    "        self.execution_history = []\n",
    "    \n",
    "    def calculate_slippage(self, order_amount, avg_volume):\n",
    "        \"\"\"Calculate slippage based on order size and volume\n",
    "        åŸºäºè®¢å•å¤§å°å’Œæˆäº¤é‡è®¡ç®—æ»‘ç‚¹\n",
    "        \"\"\"\n",
    "        \n",
    "        # Basic slippage model / åŸºç¡€æ»‘ç‚¹æ¨¡å‹\n",
    "        base_slippage = self.slippage_rate\n",
    "        \n",
    "        # Adjust for order size relative to volume / æ ¹æ®è®¢å•ç›¸å¯¹æˆäº¤é‡è°ƒæ•´\n",
    "        if avg_volume > 0:\n",
    "            size_impact = order_amount / avg_volume\n",
    "            size_impact = min(size_impact, 0.1)  # Cap at 10% of volume\n",
    "        else:\n",
    "            size_impact = 0.01\n",
    "        \n",
    "        total_slippage = base_slippage * (1 + size_impact * 10)\n",
    "        \n",
    "        return total_slippage\n",
    "    \n",
    "    def calculate_market_impact(self, order_amount, market_cap):\n",
    "        \"\"\"Calculate market impact of large orders\n",
    "        è®¡ç®—å¤§é¢è®¢å•çš„å¸‚åœºå†²å‡»\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.market_impact_model == \"linear\":\n",
    "            # Linear impact model / çº¿æ€§å†²å‡»æ¨¡å‹\n",
    "            impact = order_amount / market_cap * 0.1\n",
    "        elif self.market_impact_model == \"sqrt\":\n",
    "            # Square root impact model / å¹³æ–¹æ ¹å†²å‡»æ¨¡å‹\n",
    "            impact = np.sqrt(order_amount / market_cap) * 0.05\n",
    "        else:\n",
    "            impact = 0\n",
    "        \n",
    "        return min(impact, 0.02)  # Cap at 2% impact\n",
    "    \n",
    "    def execute_orders(self, orders, current_date):\n",
    "        \"\"\"Execute orders with realistic constraints\n",
    "        ä»¥ç°å®çº¦æŸæ‰§è¡Œè®¢å•\n",
    "        \"\"\"\n",
    "        \n",
    "        executed_orders = []\n",
    "        \n",
    "        for order in orders:\n",
    "            # Simulate execution with slippage / æ¨¡æ‹Ÿå¸¦æ»‘ç‚¹çš„æ‰§è¡Œ\n",
    "            avg_volume = 1000000  # Placeholder / å ä½ç¬¦\n",
    "            market_cap = 1000000000  # Placeholder / å ä½ç¬¦\n",
    "            \n",
    "            slippage = self.calculate_slippage(order.amount, avg_volume)\n",
    "            market_impact = self.calculate_market_impact(order.amount, market_cap)\n",
    "            \n",
    "            # Adjust execution price / è°ƒæ•´æ‰§è¡Œä»·æ ¼\n",
    "            execution_cost = slippage + market_impact\n",
    "            \n",
    "            # Record execution / è®°å½•æ‰§è¡Œ\n",
    "            self.execution_history.append({\n",
    "                'date': current_date,\n",
    "                'stock': order.stock_id,\n",
    "                'amount': order.amount,\n",
    "                'slippage': slippage,\n",
    "                'market_impact': market_impact,\n",
    "                'total_cost': execution_cost\n",
    "            })\n",
    "            \n",
    "            executed_orders.append(order)\n",
    "        \n",
    "        return executed_orders\n",
    "\n",
    "# Create advanced executor / åˆ›å»ºé«˜çº§æ‰§è¡Œå™¨\n",
    "advanced_executor = AdvancedExecutor(\n",
    "    time_per_step=\"day\",\n",
    "    slippage_rate=0.001,\n",
    "    market_impact_model=\"linear\"\n",
    ")\n",
    "\n",
    "print(\"Advanced Executor created\")\n",
    "print(f\"  Slippage rate: 0.1%\")\n",
    "print(f\"  Market impact model: linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Portfolio Analysis / ç»„åˆåˆ†æ <a id='portfolio-analysis'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive portfolio analysis / ç»¼åˆç»„åˆåˆ†æ\n",
    "\n",
    "def analyze_portfolio(portfolio_metrics, benchmark_returns=None):\n",
    "    \"\"\"Comprehensive portfolio analysis\n",
    "    ç»¼åˆç»„åˆåˆ†æ\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract key metrics / æå–å…³é”®æŒ‡æ ‡\n",
    "    if 'return' in portfolio_metrics:\n",
    "        returns = portfolio_metrics['return']\n",
    "    else:\n",
    "        # Generate sample returns for demonstration\n",
    "        dates = pd.date_range(exp_config['test_start'], exp_config['test_end'], freq='D')\n",
    "        returns = pd.Series(np.random.randn(len(dates)) * 0.01, index=dates)\n",
    "    \n",
    "    # Calculate cumulative returns / è®¡ç®—ç´¯ç§¯æ”¶ç›Š\n",
    "    cumulative_returns = (1 + returns).cumprod()\n",
    "    \n",
    "    # Performance metrics / æ€§èƒ½æŒ‡æ ‡\n",
    "    metrics = {\n",
    "        'Total Return': cumulative_returns.iloc[-1] - 1,\n",
    "        'Annual Return': (cumulative_returns.iloc[-1] ** (252/len(returns))) - 1,\n",
    "        'Volatility': returns.std() * np.sqrt(252),\n",
    "        'Sharpe Ratio': (returns.mean() / returns.std()) * np.sqrt(252) if returns.std() > 0 else 0,\n",
    "        'Max Drawdown': calculate_max_drawdown(cumulative_returns),\n",
    "        'Calmar Ratio': 0,  # Will calculate below\n",
    "        'Win Rate': (returns > 0).mean(),\n",
    "        'Best Day': returns.max(),\n",
    "        'Worst Day': returns.min(),\n",
    "        'Skewness': returns.skew(),\n",
    "        'Kurtosis': returns.kurtosis()\n",
    "    }\n",
    "    \n",
    "    # Calculate Calmar ratio / è®¡ç®—Calmaræ¯”ç‡\n",
    "    if metrics['Max Drawdown'] != 0:\n",
    "        metrics['Calmar Ratio'] = metrics['Annual Return'] / abs(metrics['Max Drawdown'])\n",
    "    \n",
    "    return metrics, returns, cumulative_returns\n",
    "\n",
    "def calculate_max_drawdown(cumulative_returns):\n",
    "    \"\"\"Calculate maximum drawdown / è®¡ç®—æœ€å¤§å›æ’¤\"\"\"\n",
    "    running_max = cumulative_returns.expanding().max()\n",
    "    drawdown = (cumulative_returns - running_max) / running_max\n",
    "    return drawdown.min()\n",
    "\n",
    "# Analyze portfolio / åˆ†æç»„åˆ\n",
    "metrics, returns, cumulative_returns = analyze_portfolio(portfolio_metrics)\n",
    "\n",
    "# Display metrics / æ˜¾ç¤ºæŒ‡æ ‡\n",
    "print(\"Portfolio Performance Metrics / ç»„åˆæ€§èƒ½æŒ‡æ ‡:\")\n",
    "print(\"=\"*50)\n",
    "for metric, value in metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        if 'Return' in metric or 'Rate' in metric or 'Volatility' in metric:\n",
    "            print(f\"{metric:20}: {value:>10.2%}\")\n",
    "        else:\n",
    "            print(f\"{metric:20}: {value:>10.4f}\")\n",
    "    else:\n",
    "        print(f\"{metric:20}: {value:>10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio visualization / ç»„åˆå¯è§†åŒ–\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Portfolio Analysis Dashboard / ç»„åˆåˆ†æä»ªè¡¨æ¿', fontsize=16)\n",
    "\n",
    "# 1. Cumulative returns / ç´¯ç§¯æ”¶ç›Š\n",
    "axes[0, 0].plot(cumulative_returns.index, cumulative_returns.values, linewidth=2)\n",
    "axes[0, 0].set_title('Cumulative Returns / ç´¯ç§¯æ”¶ç›Š')\n",
    "axes[0, 0].set_xlabel('Date / æ—¥æœŸ')\n",
    "axes[0, 0].set_ylabel('Cumulative Return / ç´¯ç§¯æ”¶ç›Š')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Daily returns distribution / æ—¥æ”¶ç›Šåˆ†å¸ƒ\n",
    "axes[0, 1].hist(returns, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[0, 1].set_title('Returns Distribution / æ”¶ç›Šåˆ†å¸ƒ')\n",
    "axes[0, 1].set_xlabel('Daily Return / æ—¥æ”¶ç›Š')\n",
    "axes[0, 1].set_ylabel('Frequency / é¢‘ç‡')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Rolling volatility / æ»šåŠ¨æ³¢åŠ¨ç‡\n",
    "rolling_vol = returns.rolling(window=60).std() * np.sqrt(252)\n",
    "axes[0, 2].plot(rolling_vol.index, rolling_vol.values, linewidth=2, color='orange')\n",
    "axes[0, 2].set_title('60-Day Rolling Volatility / 60æ—¥æ»šåŠ¨æ³¢åŠ¨ç‡')\n",
    "axes[0, 2].set_xlabel('Date / æ—¥æœŸ')\n",
    "axes[0, 2].set_ylabel('Annualized Volatility / å¹´åŒ–æ³¢åŠ¨ç‡')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Drawdown / å›æ’¤\n",
    "running_max = cumulative_returns.expanding().max()\n",
    "drawdown = (cumulative_returns - running_max) / running_max\n",
    "axes[1, 0].fill_between(drawdown.index, drawdown.values, 0, alpha=0.7, color='red')\n",
    "axes[1, 0].set_title('Drawdown / å›æ’¤')\n",
    "axes[1, 0].set_xlabel('Date / æ—¥æœŸ')\n",
    "axes[1, 0].set_ylabel('Drawdown / å›æ’¤')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Rolling Sharpe ratio / æ»šåŠ¨å¤æ™®æ¯”ç‡\n",
    "rolling_sharpe = (returns.rolling(window=60).mean() / returns.rolling(window=60).std()) * np.sqrt(252)\n",
    "axes[1, 1].plot(rolling_sharpe.index, rolling_sharpe.values, linewidth=2, color='green')\n",
    "axes[1, 1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1, 1].set_title('60-Day Rolling Sharpe Ratio / 60æ—¥æ»šåŠ¨å¤æ™®æ¯”ç‡')\n",
    "axes[1, 1].set_xlabel('Date / æ—¥æœŸ')\n",
    "axes[1, 1].set_ylabel('Sharpe Ratio / å¤æ™®æ¯”ç‡')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Q-Q plot / Q-Qå›¾\n",
    "from scipy import stats\n",
    "stats.probplot(returns, dist=\"norm\", plot=axes[1, 2])\n",
    "axes[1, 2].set_title('Q-Q Plot / Q-Qå›¾')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Risk Metrics / é£é™©æŒ‡æ ‡ <a id='risk-metrics'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive risk analysis / ç»¼åˆé£é™©åˆ†æ\n",
    "\n",
    "def calculate_risk_metrics(returns, confidence_level=0.95):\n",
    "    \"\"\"Calculate comprehensive risk metrics\n",
    "    è®¡ç®—ç»¼åˆé£é™©æŒ‡æ ‡\n",
    "    \"\"\"\n",
    "    \n",
    "    # Basic statistics / åŸºç¡€ç»Ÿè®¡\n",
    "    risk_metrics = {\n",
    "        'Volatility (Annual)': returns.std() * np.sqrt(252),\n",
    "        'Downside Volatility': returns[returns < 0].std() * np.sqrt(252),\n",
    "        'Upside Volatility': returns[returns > 0].std() * np.sqrt(252),\n",
    "    }\n",
    "    \n",
    "    # Value at Risk (VaR) / é£é™©ä»·å€¼\n",
    "    var_percentile = (1 - confidence_level) * 100\n",
    "    risk_metrics['VaR (95%)'] = np.percentile(returns, var_percentile)\n",
    "    risk_metrics['VaR (99%)'] = np.percentile(returns, 1)\n",
    "    \n",
    "    # Conditional VaR (CVaR) / æ¡ä»¶é£é™©ä»·å€¼\n",
    "    var_threshold = risk_metrics['VaR (95%)']\n",
    "    risk_metrics['CVaR (95%)'] = returns[returns <= var_threshold].mean()\n",
    "    \n",
    "    # Maximum consecutive losses / æœ€å¤§è¿ç»­äºæŸ\n",
    "    consecutive_losses = 0\n",
    "    max_consecutive_losses = 0\n",
    "    for ret in returns:\n",
    "        if ret < 0:\n",
    "            consecutive_losses += 1\n",
    "            max_consecutive_losses = max(max_consecutive_losses, consecutive_losses)\n",
    "        else:\n",
    "            consecutive_losses = 0\n",
    "    risk_metrics['Max Consecutive Losses'] = max_consecutive_losses\n",
    "    \n",
    "    # Sortino ratio / ç´¢æè¯ºæ¯”ç‡\n",
    "    downside_returns = returns[returns < 0]\n",
    "    if len(downside_returns) > 0:\n",
    "        downside_std = downside_returns.std()\n",
    "        if downside_std > 0:\n",
    "            risk_metrics['Sortino Ratio'] = (returns.mean() / downside_std) * np.sqrt(252)\n",
    "        else:\n",
    "            risk_metrics['Sortino Ratio'] = np.inf\n",
    "    else:\n",
    "        risk_metrics['Sortino Ratio'] = np.inf\n",
    "    \n",
    "    # Omega ratio / æ¬§ç±³ä¼½æ¯”ç‡\n",
    "    threshold = 0\n",
    "    gains = returns[returns > threshold] - threshold\n",
    "    losses = threshold - returns[returns <= threshold]\n",
    "    if losses.sum() > 0:\n",
    "        risk_metrics['Omega Ratio'] = gains.sum() / losses.sum()\n",
    "    else:\n",
    "        risk_metrics['Omega Ratio'] = np.inf\n",
    "    \n",
    "    # Tail ratio / å°¾éƒ¨æ¯”ç‡\n",
    "    right_tail = np.percentile(returns, 95)\n",
    "    left_tail = abs(np.percentile(returns, 5))\n",
    "    if left_tail > 0:\n",
    "        risk_metrics['Tail Ratio'] = right_tail / left_tail\n",
    "    else:\n",
    "        risk_metrics['Tail Ratio'] = np.inf\n",
    "    \n",
    "    return risk_metrics\n",
    "\n",
    "# Calculate risk metrics / è®¡ç®—é£é™©æŒ‡æ ‡\n",
    "risk_metrics = calculate_risk_metrics(returns)\n",
    "\n",
    "print(\"Risk Metrics / é£é™©æŒ‡æ ‡:\")\n",
    "print(\"=\"*50)\n",
    "for metric, value in risk_metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        if value == np.inf:\n",
    "            print(f\"{metric:30}: {'Infinity':>15}\")\n",
    "        elif 'Ratio' in metric:\n",
    "            print(f\"{metric:30}: {value:>15.4f}\")\n",
    "        else:\n",
    "            print(f\"{metric:30}: {value:>15.4%}\")\n",
    "    else:\n",
    "        print(f\"{metric:30}: {value:>15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk decomposition / é£é™©åˆ†è§£\n",
    "\n",
    "def risk_decomposition(returns, market_returns=None):\n",
    "    \"\"\"Decompose portfolio risk into systematic and idiosyncratic components\n",
    "    å°†ç»„åˆé£é™©åˆ†è§£ä¸ºç³»ç»Ÿæ€§å’Œç‰¹è´¨æ€§æˆåˆ†\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate sample market returns if not provided / å¦‚æœæœªæä¾›åˆ™ç”Ÿæˆæ ·æœ¬å¸‚åœºæ”¶ç›Š\n",
    "    if market_returns is None:\n",
    "        market_returns = returns + np.random.randn(len(returns)) * 0.005\n",
    "    \n",
    "    # Ensure alignment / ç¡®ä¿å¯¹é½\n",
    "    aligned = pd.DataFrame({\n",
    "        'portfolio': returns,\n",
    "        'market': market_returns\n",
    "    }).dropna()\n",
    "    \n",
    "    # Calculate beta / è®¡ç®—è´å¡”\n",
    "    covariance = aligned.cov()\n",
    "    beta = covariance.loc['portfolio', 'market'] / covariance.loc['market', 'market']\n",
    "    \n",
    "    # Systematic and idiosyncratic returns / ç³»ç»Ÿæ€§å’Œç‰¹è´¨æ€§æ”¶ç›Š\n",
    "    systematic_returns = beta * aligned['market']\n",
    "    idiosyncratic_returns = aligned['portfolio'] - systematic_returns\n",
    "    \n",
    "    # Risk decomposition / é£é™©åˆ†è§£\n",
    "    total_variance = aligned['portfolio'].var()\n",
    "    systematic_variance = systematic_returns.var()\n",
    "    idiosyncratic_variance = idiosyncratic_returns.var()\n",
    "    \n",
    "    decomposition = {\n",
    "        'Beta': beta,\n",
    "        'Total Risk (Annual)': np.sqrt(total_variance * 252),\n",
    "        'Systematic Risk (Annual)': np.sqrt(systematic_variance * 252),\n",
    "        'Idiosyncratic Risk (Annual)': np.sqrt(idiosyncratic_variance * 252),\n",
    "        'Systematic Risk %': systematic_variance / total_variance,\n",
    "        'Idiosyncratic Risk %': idiosyncratic_variance / total_variance,\n",
    "        'R-squared': (systematic_variance / total_variance) if total_variance > 0 else 0\n",
    "    }\n",
    "    \n",
    "    return decomposition, systematic_returns, idiosyncratic_returns\n",
    "\n",
    "# Perform risk decomposition / æ‰§è¡Œé£é™©åˆ†è§£\n",
    "decomposition, sys_returns, idio_returns = risk_decomposition(returns)\n",
    "\n",
    "print(\"Risk Decomposition / é£é™©åˆ†è§£:\")\n",
    "print(\"=\"*50)\n",
    "for metric, value in decomposition.items():\n",
    "    if '%' in metric or 'Risk' in metric:\n",
    "        print(f\"{metric:30}: {value:>15.2%}\")\n",
    "    else:\n",
    "        print(f\"{metric:30}: {value:>15.4f}\")\n",
    "\n",
    "# Visualize risk decomposition / å¯è§†åŒ–é£é™©åˆ†è§£\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Risk contribution pie chart / é£é™©è´¡çŒ®é¥¼å›¾\n",
    "risk_contrib = [decomposition['Systematic Risk %'], decomposition['Idiosyncratic Risk %']]\n",
    "axes[0].pie(risk_contrib, labels=['Systematic', 'Idiosyncratic'], \n",
    "           autopct='%1.1f%%', startangle=90)\n",
    "axes[0].set_title('Risk Decomposition / é£é™©åˆ†è§£')\n",
    "\n",
    "# Time series of risk components / é£é™©æˆåˆ†æ—¶é—´åºåˆ—\n",
    "axes[1].plot(sys_returns.index, sys_returns.cumsum(), label='Systematic', linewidth=2)\n",
    "axes[1].plot(idio_returns.index, idio_returns.cumsum(), label='Idiosyncratic', linewidth=2)\n",
    "axes[1].set_title('Cumulative Risk Components / ç´¯ç§¯é£é™©æˆåˆ†')\n",
    "axes[1].set_xlabel('Date / æ—¥æœŸ')\n",
    "axes[1].set_ylabel('Cumulative Return / ç´¯ç§¯æ”¶ç›Š')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Attribution / ä¸šç»©å½’å›  <a id='attribution'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance attribution analysis / ä¸šç»©å½’å› åˆ†æ\n",
    "\n",
    "class PerformanceAttribution:\n",
    "    \"\"\"Performance attribution framework / ä¸šç»©å½’å› æ¡†æ¶\"\"\"\n",
    "    \n",
    "    def __init__(self, portfolio_returns, benchmark_returns, positions=None):\n",
    "        self.portfolio_returns = portfolio_returns\n",
    "        self.benchmark_returns = benchmark_returns\n",
    "        self.positions = positions\n",
    "    \n",
    "    def brinson_attribution(self):\n",
    "        \"\"\"Brinson attribution model / Brinsonå½’å› æ¨¡å‹\n",
    "        Decomposes excess returns into allocation and selection effects\n",
    "        å°†è¶…é¢æ”¶ç›Šåˆ†è§£ä¸ºé…ç½®æ•ˆåº”å’Œé€‰æ‹©æ•ˆåº”\n",
    "        \"\"\"\n",
    "        \n",
    "        # Simplified Brinson attribution / ç®€åŒ–çš„Brinsonå½’å› \n",
    "        # In practice, this would use sector/asset class data\n",
    "        \n",
    "        # Total effect / æ€»æ•ˆåº”\n",
    "        total_effect = self.portfolio_returns.mean() - self.benchmark_returns.mean()\n",
    "        \n",
    "        # Allocation effect (simplified) / é…ç½®æ•ˆåº”ï¼ˆç®€åŒ–ï¼‰\n",
    "        # This would normally compare sector weights\n",
    "        allocation_effect = total_effect * 0.4  # Placeholder\n",
    "        \n",
    "        # Selection effect (simplified) / é€‰æ‹©æ•ˆåº”ï¼ˆç®€åŒ–ï¼‰\n",
    "        # This would normally compare stock selection within sectors\n",
    "        selection_effect = total_effect * 0.6  # Placeholder\n",
    "        \n",
    "        # Interaction effect / äº¤äº’æ•ˆåº”\n",
    "        interaction_effect = total_effect - allocation_effect - selection_effect\n",
    "        \n",
    "        return {\n",
    "            'Total Effect': total_effect * 252,  # Annualized\n",
    "            'Allocation Effect': allocation_effect * 252,\n",
    "            'Selection Effect': selection_effect * 252,\n",
    "            'Interaction Effect': interaction_effect * 252\n",
    "        }\n",
    "    \n",
    "    def factor_attribution(self, factor_returns=None):\n",
    "        \"\"\"Factor-based attribution / å› å­å½’å› \n",
    "        Attributes returns to various risk factors\n",
    "        å°†æ”¶ç›Šå½’å› äºå„ç§é£é™©å› å­\n",
    "        \"\"\"\n",
    "        \n",
    "        if factor_returns is None:\n",
    "            # Generate sample factor returns / ç”Ÿæˆæ ·æœ¬å› å­æ”¶ç›Š\n",
    "            factor_returns = pd.DataFrame({\n",
    "                'Market': self.benchmark_returns,\n",
    "                'Size': np.random.randn(len(self.portfolio_returns)) * 0.005,\n",
    "                'Value': np.random.randn(len(self.portfolio_returns)) * 0.003,\n",
    "                'Momentum': np.random.randn(len(self.portfolio_returns)) * 0.004,\n",
    "                'Quality': np.random.randn(len(self.portfolio_returns)) * 0.002\n",
    "            })\n",
    "        \n",
    "        # Run factor regression / è¿è¡Œå› å­å›å½’\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        \n",
    "        model = LinearRegression()\n",
    "        X = factor_returns.values\n",
    "        y = self.portfolio_returns.values\n",
    "        \n",
    "        # Fit model / æ‹Ÿåˆæ¨¡å‹\n",
    "        model.fit(X, y)\n",
    "        \n",
    "        # Factor loadings / å› å­è½½è·\n",
    "        loadings = dict(zip(factor_returns.columns, model.coef_))\n",
    "        alpha = model.intercept_\n",
    "        \n",
    "        # Factor contributions / å› å­è´¡çŒ®\n",
    "        contributions = {}\n",
    "        for factor, loading in loadings.items():\n",
    "            factor_contribution = loading * factor_returns[factor].mean() * 252\n",
    "            contributions[f'{factor} Contribution'] = factor_contribution\n",
    "        \n",
    "        contributions['Alpha'] = alpha * 252\n",
    "        contributions['R-squared'] = model.score(X, y)\n",
    "        \n",
    "        return contributions, loadings\n",
    "    \n",
    "    def time_attribution(self):\n",
    "        \"\"\"Time-based attribution / åŸºäºæ—¶é—´çš„å½’å› \n",
    "        Analyzes performance across different time periods\n",
    "        åˆ†æä¸åŒæ—¶é—´æ®µçš„è¡¨ç°\n",
    "        \"\"\"\n",
    "        \n",
    "        # Monthly returns / æœˆåº¦æ”¶ç›Š\n",
    "        monthly_portfolio = self.portfolio_returns.resample('M').apply(lambda x: (1 + x).prod() - 1)\n",
    "        monthly_benchmark = self.benchmark_returns.resample('M').apply(lambda x: (1 + x).prod() - 1)\n",
    "        \n",
    "        # Quarterly returns / å­£åº¦æ”¶ç›Š\n",
    "        quarterly_portfolio = self.portfolio_returns.resample('Q').apply(lambda x: (1 + x).prod() - 1)\n",
    "        quarterly_benchmark = self.benchmark_returns.resample('Q').apply(lambda x: (1 + x).prod() - 1)\n",
    "        \n",
    "        return {\n",
    "            'Monthly': {\n",
    "                'Portfolio Mean': monthly_portfolio.mean() * 12,\n",
    "                'Benchmark Mean': monthly_benchmark.mean() * 12,\n",
    "                'Excess Return': (monthly_portfolio.mean() - monthly_benchmark.mean()) * 12,\n",
    "                'Information Ratio': (monthly_portfolio - monthly_benchmark).mean() / (monthly_portfolio - monthly_benchmark).std() * np.sqrt(12)\n",
    "            },\n",
    "            'Quarterly': {\n",
    "                'Portfolio Mean': quarterly_portfolio.mean() * 4,\n",
    "                'Benchmark Mean': quarterly_benchmark.mean() * 4,\n",
    "                'Excess Return': (quarterly_portfolio.mean() - quarterly_benchmark.mean()) * 4,\n",
    "                'Information Ratio': (quarterly_portfolio - quarterly_benchmark).mean() / (quarterly_portfolio - quarterly_benchmark).std() * np.sqrt(4)\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Generate sample benchmark returns / ç”Ÿæˆæ ·æœ¬åŸºå‡†æ”¶ç›Š\n",
    "benchmark_returns = returns * 0.8 + np.random.randn(len(returns)) * 0.005\n",
    "\n",
    "# Perform attribution analysis / æ‰§è¡Œå½’å› åˆ†æ\n",
    "attribution = PerformanceAttribution(returns, benchmark_returns)\n",
    "\n",
    "# Brinson attribution / Brinsonå½’å› \n",
    "brinson_results = attribution.brinson_attribution()\n",
    "print(\"Brinson Attribution / Brinsonå½’å› :\")\n",
    "print(\"=\"*50)\n",
    "for effect, value in brinson_results.items():\n",
    "    print(f\"{effect:20}: {value:>10.2%}\")\n",
    "\n",
    "# Factor attribution / å› å­å½’å› \n",
    "print(\"\\nFactor Attribution / å› å­å½’å› :\")\n",
    "print(\"=\"*50)\n",
    "factor_results, loadings = attribution.factor_attribution()\n",
    "for factor, contribution in factor_results.items():\n",
    "    if 'R-squared' in factor:\n",
    "        print(f\"{factor:20}: {contribution:>10.4f}\")\n",
    "    else:\n",
    "        print(f\"{factor:20}: {contribution:>10.2%}\")\n",
    "\n",
    "# Time attribution / æ—¶é—´å½’å› \n",
    "print(\"\\nTime-based Attribution / åŸºäºæ—¶é—´çš„å½’å› :\")\n",
    "print(\"=\"*50)\n",
    "time_results = attribution.time_attribution()\n",
    "for period, metrics in time_results.items():\n",
    "    print(f\"\\n{period}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        if 'Ratio' in metric:\n",
    "            print(f\"  {metric:20}: {value:>10.4f}\")\n",
    "        else:\n",
    "            print(f\"  {metric:20}: {value:>10.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Signal Analysis / ä¿¡å·åˆ†æ <a id='signal-analysis'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal quality analysis / ä¿¡å·è´¨é‡åˆ†æ\n",
    "\n",
    "def analyze_signal_quality(predictions, returns, forward_periods=[1, 5, 10, 20]):\n",
    "    \"\"\"Analyze the quality of trading signals\n",
    "    åˆ†æäº¤æ˜“ä¿¡å·çš„è´¨é‡\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for period in forward_periods:\n",
    "        # Calculate forward returns / è®¡ç®—å‰ç»æ”¶ç›Š\n",
    "        forward_returns = returns.shift(-period)\n",
    "        \n",
    "        # Align predictions and returns / å¯¹é½é¢„æµ‹å’Œæ”¶ç›Š\n",
    "        aligned = pd.DataFrame({\n",
    "            'signal': predictions,\n",
    "            'forward_return': forward_returns\n",
    "        }).dropna()\n",
    "        \n",
    "        if len(aligned) > 0:\n",
    "            # Information Coefficient (IC) / ä¿¡æ¯ç³»æ•°\n",
    "            ic = aligned['signal'].corr(aligned['forward_return'])\n",
    "            \n",
    "            # Rank IC / æ’åºIC\n",
    "            from scipy.stats import spearmanr\n",
    "            rank_ic, _ = spearmanr(aligned['signal'], aligned['forward_return'])\n",
    "            \n",
    "            # IC by quantile / åˆ†ä½æ•°IC\n",
    "            aligned['signal_quantile'] = pd.qcut(aligned['signal'], q=5, labels=['Q1', 'Q2', 'Q3', 'Q4', 'Q5'])\n",
    "            quantile_returns = aligned.groupby('signal_quantile')['forward_return'].mean()\n",
    "            \n",
    "            # Win rate by quantile / åˆ†ä½æ•°èƒœç‡\n",
    "            quantile_winrate = aligned.groupby('signal_quantile')['forward_return'].apply(lambda x: (x > 0).mean())\n",
    "            \n",
    "            results[f'{period}D'] = {\n",
    "                'IC': ic,\n",
    "                'Rank IC': rank_ic,\n",
    "                'Top Quintile Return': quantile_returns.iloc[-1] if len(quantile_returns) > 0 else 0,\n",
    "                'Bottom Quintile Return': quantile_returns.iloc[0] if len(quantile_returns) > 0 else 0,\n",
    "                'Q5-Q1 Spread': quantile_returns.iloc[-1] - quantile_returns.iloc[0] if len(quantile_returns) > 0 else 0,\n",
    "                'Top Quintile Win Rate': quantile_winrate.iloc[-1] if len(quantile_winrate) > 0 else 0\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Analyze signal quality / åˆ†æä¿¡å·è´¨é‡\n",
    "signal_quality = analyze_signal_quality(predictions, returns)\n",
    "\n",
    "print(\"Signal Quality Analysis / ä¿¡å·è´¨é‡åˆ†æ:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create results table / åˆ›å»ºç»“æœè¡¨æ ¼\n",
    "signal_df = pd.DataFrame(signal_quality).T\n",
    "print(signal_df.round(4))\n",
    "\n",
    "# Visualize signal analysis / å¯è§†åŒ–ä¿¡å·åˆ†æ\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# 1. IC over different horizons / ä¸åŒæ—¶é—´è·¨åº¦çš„IC\n",
    "periods = list(signal_quality.keys())\n",
    "ic_values = [signal_quality[p]['IC'] for p in periods]\n",
    "rank_ic_values = [signal_quality[p]['Rank IC'] for p in periods]\n",
    "\n",
    "axes[0, 0].bar(range(len(periods)), ic_values, alpha=0.7, label='IC')\n",
    "axes[0, 0].bar(range(len(periods)), rank_ic_values, alpha=0.7, label='Rank IC')\n",
    "axes[0, 0].set_xticks(range(len(periods)))\n",
    "axes[0, 0].set_xticklabels(periods)\n",
    "axes[0, 0].set_title('Information Coefficient by Horizon / ä¸åŒæ—¶é—´è·¨åº¦çš„ä¿¡æ¯ç³»æ•°')\n",
    "axes[0, 0].set_xlabel('Forward Period / å‰ç»æœŸ')\n",
    "axes[0, 0].set_ylabel('IC Value / ICå€¼')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Quintile spreads / äº”åˆ†ä½ä»·å·®\n",
    "spreads = [signal_quality[p]['Q5-Q1 Spread'] for p in periods]\n",
    "axes[0, 1].plot(range(len(periods)), spreads, marker='o', linewidth=2, markersize=8)\n",
    "axes[0, 1].set_xticks(range(len(periods)))\n",
    "axes[0, 1].set_xticklabels(periods)\n",
    "axes[0, 1].set_title('Quintile Spread by Horizon / ä¸åŒæ—¶é—´è·¨åº¦çš„äº”åˆ†ä½ä»·å·®')\n",
    "axes[0, 1].set_xlabel('Forward Period / å‰ç»æœŸ')\n",
    "axes[0, 1].set_ylabel('Q5-Q1 Spread / äº”åˆ†ä½ä»·å·®')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Signal distribution / ä¿¡å·åˆ†å¸ƒ\n",
    "axes[1, 0].hist(predictions, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_title('Signal Distribution / ä¿¡å·åˆ†å¸ƒ')\n",
    "axes[1, 0].set_xlabel('Signal Value / ä¿¡å·å€¼')\n",
    "axes[1, 0].set_ylabel('Frequency / é¢‘ç‡')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Signal autocorrelation / ä¿¡å·è‡ªç›¸å…³\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "plot_acf(predictions.dropna(), lags=20, ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Signal Autocorrelation / ä¿¡å·è‡ªç›¸å…³')\n",
    "axes[1, 1].set_xlabel('Lag / æ»å')\n",
    "axes[1, 1].set_ylabel('Autocorrelation / è‡ªç›¸å…³')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Transaction Cost Analysis / äº¤æ˜“æˆæœ¬åˆ†æ <a id='tca'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction cost analysis / äº¤æ˜“æˆæœ¬åˆ†æ\n",
    "\n",
    "class TransactionCostAnalysis:\n",
    "    \"\"\"Comprehensive transaction cost analysis\n",
    "    ç»¼åˆäº¤æ˜“æˆæœ¬åˆ†æ\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, trades, prices):\n",
    "        self.trades = trades\n",
    "        self.prices = prices\n",
    "    \n",
    "    def calculate_costs(self, commission_rate=0.001, slippage_model='linear'):\n",
    "        \"\"\"Calculate various transaction costs\n",
    "        è®¡ç®—å„ç§äº¤æ˜“æˆæœ¬\n",
    "        \"\"\"\n",
    "        \n",
    "        total_costs = {\n",
    "            'Commission': 0,\n",
    "            'Slippage': 0,\n",
    "            'Market Impact': 0,\n",
    "            'Opportunity Cost': 0\n",
    "        }\n",
    "        \n",
    "        # Commission costs / ä½£é‡‘æˆæœ¬\n",
    "        trade_value = abs(self.trades).sum()\n",
    "        total_costs['Commission'] = trade_value * commission_rate\n",
    "        \n",
    "        # Slippage costs / æ»‘ç‚¹æˆæœ¬\n",
    "        if slippage_model == 'linear':\n",
    "            # Linear slippage model / çº¿æ€§æ»‘ç‚¹æ¨¡å‹\n",
    "            avg_trade_size = abs(self.trades).mean()\n",
    "            slippage_rate = 0.0005 * (1 + avg_trade_size / 1000000)\n",
    "            total_costs['Slippage'] = trade_value * slippage_rate\n",
    "        elif slippage_model == 'sqrt':\n",
    "            # Square root model / å¹³æ–¹æ ¹æ¨¡å‹\n",
    "            total_costs['Slippage'] = trade_value * np.sqrt(avg_trade_size / 1000000) * 0.001\n",
    "        \n",
    "        # Market impact / å¸‚åœºå†²å‡»\n",
    "        # Simplified Almgren-Chriss model\n",
    "        volatility = self.prices.pct_change().std()\n",
    "        avg_volume = 1000000  # Placeholder\n",
    "        participation_rate = abs(self.trades).sum() / avg_volume\n",
    "        total_costs['Market Impact'] = trade_value * volatility * np.sqrt(participation_rate) * 0.1\n",
    "        \n",
    "        # Opportunity cost / æœºä¼šæˆæœ¬\n",
    "        # Cost of delayed or partial execution\n",
    "        total_costs['Opportunity Cost'] = trade_value * 0.0002\n",
    "        \n",
    "        # Total cost / æ€»æˆæœ¬\n",
    "        total_costs['Total'] = sum(total_costs.values())\n",
    "        \n",
    "        return total_costs\n",
    "    \n",
    "    def analyze_trade_efficiency(self):\n",
    "        \"\"\"Analyze trading efficiency metrics\n",
    "        åˆ†æäº¤æ˜“æ•ˆç‡æŒ‡æ ‡\n",
    "        \"\"\"\n",
    "        \n",
    "        efficiency_metrics = {}\n",
    "        \n",
    "        # Turnover rate / æ¢æ‰‹ç‡\n",
    "        efficiency_metrics['Daily Turnover'] = abs(self.trades).mean()\n",
    "        efficiency_metrics['Annual Turnover'] = abs(self.trades).mean() * 252\n",
    "        \n",
    "        # Trade frequency / äº¤æ˜“é¢‘ç‡\n",
    "        efficiency_metrics['Trade Days'] = (self.trades != 0).sum()\n",
    "        efficiency_metrics['Trade Frequency'] = (self.trades != 0).mean()\n",
    "        \n",
    "        # Average trade size / å¹³å‡äº¤æ˜“è§„æ¨¡\n",
    "        non_zero_trades = self.trades[self.trades != 0]\n",
    "        if len(non_zero_trades) > 0:\n",
    "            efficiency_metrics['Avg Trade Size'] = abs(non_zero_trades).mean()\n",
    "            efficiency_metrics['Max Trade Size'] = abs(non_zero_trades).max()\n",
    "            efficiency_metrics['Trade Size Std'] = abs(non_zero_trades).std()\n",
    "        \n",
    "        return efficiency_metrics\n",
    "\n",
    "# Generate sample trade data / ç”Ÿæˆæ ·æœ¬äº¤æ˜“æ•°æ®\n",
    "trade_dates = pd.date_range(exp_config['test_start'], exp_config['test_end'], freq='D')\n",
    "trades = pd.Series(np.random.randn(len(trade_dates)) * 10000, index=trade_dates)\n",
    "trades[np.random.random(len(trades)) > 0.1] = 0  # Make 90% days no trade\n",
    "\n",
    "prices = pd.Series(100 + np.random.randn(len(trade_dates)).cumsum(), index=trade_dates)\n",
    "\n",
    "# Perform TCA / æ‰§è¡Œäº¤æ˜“æˆæœ¬åˆ†æ\n",
    "tca = TransactionCostAnalysis(trades, prices)\n",
    "\n",
    "# Calculate costs / è®¡ç®—æˆæœ¬\n",
    "costs = tca.calculate_costs()\n",
    "print(\"Transaction Cost Breakdown / äº¤æ˜“æˆæœ¬åˆ†è§£:\")\n",
    "print(\"=\"*50)\n",
    "for cost_type, amount in costs.items():\n",
    "    print(f\"{cost_type:20}: ${amount:>15,.2f}\")\n",
    "\n",
    "# Analyze efficiency / åˆ†ææ•ˆç‡\n",
    "efficiency = tca.analyze_trade_efficiency()\n",
    "print(\"\\nTrading Efficiency Metrics / äº¤æ˜“æ•ˆç‡æŒ‡æ ‡:\")\n",
    "print(\"=\"*50)\n",
    "for metric, value in efficiency.items():\n",
    "    if 'Size' in metric:\n",
    "        print(f\"{metric:20}: ${value:>15,.2f}\")\n",
    "    elif 'Frequency' in metric or 'Turnover' in metric:\n",
    "        print(f\"{metric:20}: {value:>15.2%}\")\n",
    "    else:\n",
    "        print(f\"{metric:20}: {value:>15,.0f}\")\n",
    "\n",
    "# Visualize costs / å¯è§†åŒ–æˆæœ¬\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Cost breakdown pie chart / æˆæœ¬åˆ†è§£é¥¼å›¾\n",
    "cost_values = [costs[k] for k in ['Commission', 'Slippage', 'Market Impact', 'Opportunity Cost']]\n",
    "cost_labels = ['Commission', 'Slippage', 'Market Impact', 'Opportunity']\n",
    "axes[0].pie(cost_values, labels=cost_labels, autopct='%1.1f%%', startangle=90)\n",
    "axes[0].set_title('Transaction Cost Breakdown / äº¤æ˜“æˆæœ¬åˆ†è§£')\n",
    "\n",
    "# Cumulative costs over time / ç´¯ç§¯æˆæœ¬æ—¶é—´åºåˆ—\n",
    "cumulative_trades = abs(trades).cumsum()\n",
    "cumulative_costs = cumulative_trades * 0.002  # Simplified\n",
    "axes[1].plot(cumulative_costs.index, cumulative_costs.values, linewidth=2)\n",
    "axes[1].set_title('Cumulative Transaction Costs / ç´¯ç§¯äº¤æ˜“æˆæœ¬')\n",
    "axes[1].set_xlabel('Date / æ—¥æœŸ')\n",
    "axes[1].set_ylabel('Cumulative Cost ($) / ç´¯ç§¯æˆæœ¬')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualization and Reporting / å¯è§†åŒ–ä¸æŠ¥å‘Š <a id='visualization'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive performance report generation / ç»¼åˆæ€§èƒ½æŠ¥å‘Šç”Ÿæˆ\n",
    "\n",
    "def generate_performance_report(portfolio_metrics, risk_metrics, signal_quality, costs):\n",
    "    \"\"\"Generate comprehensive performance report\n",
    "    ç”Ÿæˆç»¼åˆæ€§èƒ½æŠ¥å‘Š\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create figure with multiple subplots / åˆ›å»ºå¤šå­å›¾\n",
    "    fig = plt.figure(figsize=(20, 24))\n",
    "    gs = fig.add_gridspec(6, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Title / æ ‡é¢˜\n",
    "    fig.suptitle('Strategy Performance Report / ç­–ç•¥æ€§èƒ½æŠ¥å‘Š', fontsize=20, fontweight='bold')\n",
    "    \n",
    "    # 1. Cumulative returns comparison / ç´¯ç§¯æ”¶ç›Šå¯¹æ¯”\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    ax1.plot(cumulative_returns.index, cumulative_returns.values, label='Strategy', linewidth=2)\n",
    "    ax1.plot(cumulative_returns.index, (1 + benchmark_returns).cumprod().values, \n",
    "            label='Benchmark', linewidth=2, alpha=0.7)\n",
    "    ax1.set_title('Cumulative Returns / ç´¯ç§¯æ”¶ç›Š', fontsize=14)\n",
    "    ax1.set_xlabel('Date / æ—¥æœŸ')\n",
    "    ax1.set_ylabel('Cumulative Return / ç´¯ç§¯æ”¶ç›Š')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Monthly returns heatmap / æœˆåº¦æ”¶ç›Šçƒ­å›¾\n",
    "    ax2 = fig.add_subplot(gs[1, :])\n",
    "    monthly_returns = returns.resample('M').apply(lambda x: (1 + x).prod() - 1)\n",
    "    monthly_pivot = pd.DataFrame({\n",
    "        'Month': monthly_returns.index.month,\n",
    "        'Year': monthly_returns.index.year,\n",
    "        'Return': monthly_returns.values\n",
    "    }).pivot(index='Month', columns='Year', values='Return')\n",
    "    \n",
    "    sns.heatmap(monthly_pivot, annot=True, fmt='.1%', cmap='RdYlGn', center=0, \n",
    "               cbar_kws={'label': 'Monthly Return'}, ax=ax2)\n",
    "    ax2.set_title('Monthly Returns Heatmap / æœˆåº¦æ”¶ç›Šçƒ­å›¾', fontsize=14)\n",
    "    \n",
    "    # 3. Risk metrics / é£é™©æŒ‡æ ‡\n",
    "    ax3 = fig.add_subplot(gs[2, 0])\n",
    "    risk_keys = list(risk_metrics.keys())[:5]\n",
    "    risk_values = [risk_metrics[k] for k in risk_keys]\n",
    "    ax3.barh(risk_keys, risk_values)\n",
    "    ax3.set_title('Risk Metrics / é£é™©æŒ‡æ ‡', fontsize=12)\n",
    "    ax3.set_xlabel('Value / å€¼')\n",
    "    \n",
    "    # 4. Signal quality / ä¿¡å·è´¨é‡\n",
    "    ax4 = fig.add_subplot(gs[2, 1])\n",
    "    signal_df = pd.DataFrame(signal_quality).T\n",
    "    signal_df[['IC', 'Rank IC']].plot(kind='bar', ax=ax4)\n",
    "    ax4.set_title('Signal Quality / ä¿¡å·è´¨é‡', fontsize=12)\n",
    "    ax4.set_xlabel('Period / æœŸé—´')\n",
    "    ax4.set_ylabel('IC Value / ICå€¼')\n",
    "    ax4.legend()\n",
    "    \n",
    "    # 5. Cost breakdown / æˆæœ¬åˆ†è§£\n",
    "    ax5 = fig.add_subplot(gs[2, 2])\n",
    "    cost_values = [costs[k] for k in ['Commission', 'Slippage', 'Market Impact', 'Opportunity Cost']]\n",
    "    cost_labels = ['Commission', 'Slippage', 'Market Impact', 'Opportunity']\n",
    "    ax5.pie(cost_values, labels=cost_labels, autopct='%1.1f%%', startangle=90)\n",
    "    ax5.set_title('Transaction Costs / äº¤æ˜“æˆæœ¬', fontsize=12)\n",
    "    \n",
    "    # 6. Rolling metrics / æ»šåŠ¨æŒ‡æ ‡\n",
    "    ax6 = fig.add_subplot(gs[3, :])\n",
    "    rolling_sharpe = (returns.rolling(60).mean() / returns.rolling(60).std()) * np.sqrt(252)\n",
    "    ax6.plot(rolling_sharpe.index, rolling_sharpe.values, label='Rolling Sharpe (60D)', linewidth=2)\n",
    "    ax6.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    ax6.axhline(y=1, color='green', linestyle='--', alpha=0.5)\n",
    "    ax6.set_title('Rolling Sharpe Ratio / æ»šåŠ¨å¤æ™®æ¯”ç‡', fontsize=14)\n",
    "    ax6.set_xlabel('Date / æ—¥æœŸ')\n",
    "    ax6.set_ylabel('Sharpe Ratio / å¤æ™®æ¯”ç‡')\n",
    "    ax6.legend()\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 7. Drawdown analysis / å›æ’¤åˆ†æ\n",
    "    ax7 = fig.add_subplot(gs[4, :])\n",
    "    running_max = cumulative_returns.expanding().max()\n",
    "    drawdown = (cumulative_returns - running_max) / running_max\n",
    "    ax7.fill_between(drawdown.index, drawdown.values, 0, alpha=0.7, color='red')\n",
    "    ax7.set_title('Drawdown Analysis / å›æ’¤åˆ†æ', fontsize=14)\n",
    "    ax7.set_xlabel('Date / æ—¥æœŸ')\n",
    "    ax7.set_ylabel('Drawdown / å›æ’¤')\n",
    "    ax7.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 8. Performance summary table / æ€§èƒ½æ‘˜è¦è¡¨\n",
    "    ax8 = fig.add_subplot(gs[5, :])\n",
    "    ax8.axis('tight')\n",
    "    ax8.axis('off')\n",
    "    \n",
    "    # Create summary data / åˆ›å»ºæ‘˜è¦æ•°æ®\n",
    "    summary_data = [\n",
    "        ['Metric / æŒ‡æ ‡', 'Value / å€¼'],\n",
    "        ['Total Return / æ€»æ”¶ç›Š', f\"{(cumulative_returns.iloc[-1] - 1):.2%}\"],\n",
    "        ['Annual Return / å¹´åŒ–æ”¶ç›Š', f\"{metrics['Annual Return']:.2%}\"],\n",
    "        ['Volatility / æ³¢åŠ¨ç‡', f\"{metrics['Volatility']:.2%}\"],\n",
    "        ['Sharpe Ratio / å¤æ™®æ¯”ç‡', f\"{metrics['Sharpe Ratio']:.4f}\"],\n",
    "        ['Max Drawdown / æœ€å¤§å›æ’¤', f\"{metrics['Max Drawdown']:.2%}\"],\n",
    "        ['Calmar Ratio / å¡å°”ç›æ¯”ç‡', f\"{metrics['Calmar Ratio']:.4f}\"],\n",
    "        ['Win Rate / èƒœç‡', f\"{metrics['Win Rate']:.2%}\"],\n",
    "        ['Best Day / æœ€ä½³æ—¥', f\"{metrics['Best Day']:.2%}\"],\n",
    "        ['Worst Day / æœ€å·®æ—¥', f\"{metrics['Worst Day']:.2%}\"],\n",
    "        ['Total Cost / æ€»æˆæœ¬', f\"${costs['Total']:,.2f}\"]\n",
    "    ]\n",
    "    \n",
    "    table = ax8.table(cellText=summary_data[1:], colLabels=summary_data[0],\n",
    "                     cellLoc='center', loc='center', colWidths=[0.5, 0.5])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(11)\n",
    "    table.scale(1, 2)\n",
    "    \n",
    "    # Style the table / è®¾ç½®è¡¨æ ¼æ ·å¼\n",
    "    for i in range(len(summary_data)):\n",
    "        if i == 0:\n",
    "            for j in range(2):\n",
    "                table[(i, j)].set_facecolor('#40466e')\n",
    "                table[(i, j)].set_text_props(weight='bold', color='white')\n",
    "        else:\n",
    "            for j in range(2):\n",
    "                table[(i, j)].set_facecolor('#f0f0f0' if i % 2 == 0 else 'white')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Generate report / ç”ŸæˆæŠ¥å‘Š\n",
    "report_fig = generate_performance_report(portfolio_metrics, risk_metrics, signal_quality, costs)\n",
    "plt.show()\n",
    "\n",
    "# Save report / ä¿å­˜æŠ¥å‘Š\n",
    "report_fig.savefig('performance_report.pdf', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nâœ… Performance report saved as 'performance_report.pdf'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary / æ€»ç»“\n",
    "\n",
    "### What we covered / æœ¬èŠ‚å†…å®¹\n",
    "\n",
    "1. **Backtesting Framework** - Complete infrastructure for strategy testing / å®Œæ•´çš„ç­–ç•¥æµ‹è¯•åŸºç¡€è®¾æ–½\n",
    "2. **Trading Strategies** - Top-K, signal-based, and custom strategies / Top-Kã€åŸºäºä¿¡å·å’Œè‡ªå®šä¹‰ç­–ç•¥\n",
    "3. **Execution Management** - Order generation and execution with realistic constraints / å¸¦ç°å®çº¦æŸçš„è®¢å•ç”Ÿæˆå’Œæ‰§è¡Œ\n",
    "4. **Portfolio Analysis** - Comprehensive performance metrics and visualization / ç»¼åˆæ€§èƒ½æŒ‡æ ‡å’Œå¯è§†åŒ–\n",
    "5. **Risk Metrics** - VaR, CVaR, drawdown, and risk decomposition / VaRã€CVaRã€å›æ’¤å’Œé£é™©åˆ†è§£\n",
    "6. **Performance Attribution** - Brinson, factor, and time-based attribution / Brinsonã€å› å­å’ŒåŸºäºæ—¶é—´çš„å½’å› \n",
    "7. **Signal Analysis** - IC, Rank IC, and signal quality metrics / ICã€Rank ICå’Œä¿¡å·è´¨é‡æŒ‡æ ‡\n",
    "8. **Transaction Cost Analysis** - Commission, slippage, and market impact / ä½£é‡‘ã€æ»‘ç‚¹å’Œå¸‚åœºå†²å‡»\n",
    "9. **Reporting** - Professional performance reports and dashboards / ä¸“ä¸šçš„æ€§èƒ½æŠ¥å‘Šå’Œä»ªè¡¨æ¿\n",
    "\n",
    "### Key Takeaways / å…³é”®è¦ç‚¹\n",
    "\n",
    "- **Realistic Backtesting**: Include transaction costs and market constraints / åŒ…å«äº¤æ˜“æˆæœ¬å’Œå¸‚åœºçº¦æŸ\n",
    "- **Risk Management**: Monitor multiple risk metrics continuously / æŒç»­ç›‘æ§å¤šä¸ªé£é™©æŒ‡æ ‡\n",
    "- **Signal Quality**: Validate predictions before deployment / éƒ¨ç½²å‰éªŒè¯é¢„æµ‹\n",
    "- **Attribution Analysis**: Understand sources of returns / ç†è§£æ”¶ç›Šæ¥æº\n",
    "- **Cost Awareness**: Transaction costs can significantly impact returns / äº¤æ˜“æˆæœ¬å¯èƒ½æ˜¾è‘—å½±å“æ”¶ç›Š\n",
    "\n",
    "### Next Steps / ä¸‹ä¸€æ­¥\n",
    "\n",
    "Continue with **[05_utils_and_helpers.ipynb](./05_utils_and_helpers.ipynb)** to learn about:\n",
    "- Utility functions and helpers / å·¥å…·å‡½æ•°å’Œè¾…åŠ©åŠŸèƒ½\n",
    "- Advanced Qlib features / é«˜çº§QlibåŠŸèƒ½\n",
    "- Best practices and tips / æœ€ä½³å®è·µå’ŒæŠ€å·§"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}