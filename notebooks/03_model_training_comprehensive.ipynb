{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Model Training and Optimization\n",
    "# ç¬¬ä¸‰ç« ï¼šæ¨¡å‹è®­ç»ƒä¸ä¼˜åŒ–\n",
    "\n",
    "**Author**: Microsoft Qlib Team  \n",
    "**License**: MIT License  \n",
    "**Last Updated**: 2025-01-09\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š Table of Contents / ç›®å½•\n",
    "\n",
    "### Part 1: Model Fundamentals / æ¨¡å‹åŸºç¡€\n",
    "1. [Model Interface and Architecture / æ¨¡å‹æ¥å£ä¸æ¶æ„](#model-interface)\n",
    "2. [Dataset Preparation / æ•°æ®é›†å‡†å¤‡](#dataset-prep)\n",
    "3. [Training Pipeline / è®­ç»ƒç®¡é“](#training-pipeline)\n",
    "\n",
    "### Part 2: Tree-Based Models / æ ‘æ¨¡å‹\n",
    "4. [LightGBM Models / LightGBMæ¨¡å‹](#lightgbm)\n",
    "5. [XGBoost Models / XGBoostæ¨¡å‹](#xgboost)\n",
    "6. [CatBoost Models / CatBoostæ¨¡å‹](#catboost)\n",
    "7. [Tree Model Comparison / æ ‘æ¨¡å‹å¯¹æ¯”](#tree-comparison)\n",
    "\n",
    "### Part 3: Deep Learning Models / æ·±åº¦å­¦ä¹ æ¨¡å‹\n",
    "8. [Neural Network Basics / ç¥ç»ç½‘ç»œåŸºç¡€](#nn-basics)\n",
    "9. [MLP for Stock Prediction / ç”¨äºè‚¡ç¥¨é¢„æµ‹çš„MLP](#mlp)\n",
    "10. [LSTM and GRU Models / LSTMå’ŒGRUæ¨¡å‹](#lstm-gru)\n",
    "11. [Transformer Models / Transformeræ¨¡å‹](#transformer)\n",
    "12. [Graph Neural Networks / å›¾ç¥ç»ç½‘ç»œ](#gnn)\n",
    "\n",
    "### Part 4: Model Optimization / æ¨¡å‹ä¼˜åŒ–\n",
    "13. [Hyperparameter Tuning / è¶…å‚æ•°è°ƒä¼˜](#hyperparameter)\n",
    "14. [Feature Selection / ç‰¹å¾é€‰æ‹©](#feature-selection)\n",
    "15. [Ensemble Methods / é›†æˆæ–¹æ³•](#ensemble)\n",
    "16. [Cross-Validation Strategies / äº¤å‰éªŒè¯ç­–ç•¥](#cross-validation)\n",
    "\n",
    "### Part 5: Production Deployment / ç”Ÿäº§éƒ¨ç½²\n",
    "17. [Model Persistence / æ¨¡å‹æŒä¹…åŒ–](#persistence)\n",
    "18. [Online Learning / åœ¨çº¿å­¦ä¹ ](#online-learning)\n",
    "19. [Model Monitoring / æ¨¡å‹ç›‘æ§](#monitoring)\n",
    "20. [Best Practices / æœ€ä½³å®è·µ](#best-practices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports / è®¾ç½®å’Œå¯¼å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports / å¿…è¦å¯¼å…¥\n",
    "import qlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "from datetime import datetime\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Qlib imports / Qlibå¯¼å…¥\n",
    "from qlib.data import D\n",
    "from qlib.config import C\n",
    "from qlib.workflow import R\n",
    "from qlib.utils import init_instance_by_config\n",
    "from qlib.model.base import Model\n",
    "from qlib.data.dataset import DatasetH, TSDatasetH\n",
    "\n",
    "# Model imports / æ¨¡å‹å¯¼å…¥\n",
    "from qlib.contrib.model.gbdt import LGBModel\n",
    "from qlib.contrib.model.xgboost import XGBModel\n",
    "from qlib.contrib.model.catboost import CatBoostModel\n",
    "from qlib.contrib.model.pytorch_nn import DNNModel\n",
    "from qlib.contrib.model.pytorch_lstm import LSTMModel\n",
    "from qlib.contrib.model.pytorch_gru import GRUModel\n",
    "\n",
    "# Visualization settings / å¯è§†åŒ–è®¾ç½®\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Qlib / åˆå§‹åŒ–Qlib\n",
    "qlib.init()\n",
    "\n",
    "# Global configuration / å…¨å±€é…ç½®\n",
    "MARKET = \"csi300\"  # æ²ªæ·±300\n",
    "BENCHMARK = \"SH000300\"  # åŸºå‡†æŒ‡æ•°\n",
    "EXP_NAME = \"model_training_exp\"  # å®éªŒåç§°\n",
    "\n",
    "# Time periods / æ—¶é—´æ®µ\n",
    "TRAIN_START = \"2008-01-01\"\n",
    "TRAIN_END = \"2014-12-31\"\n",
    "VALID_START = \"2015-01-01\"\n",
    "VALID_END = \"2016-12-31\"\n",
    "TEST_START = \"2017-01-01\"\n",
    "TEST_END = \"2020-08-01\"\n",
    "\n",
    "print(f\"Market: {MARKET}\")\n",
    "print(f\"Training: {TRAIN_START} to {TRAIN_END}\")\n",
    "print(f\"Validation: {VALID_START} to {VALID_END}\")\n",
    "print(f\"Testing: {TEST_START} to {TEST_END}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Model Fundamentals / æ¨¡å‹åŸºç¡€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Interface and Architecture / æ¨¡å‹æ¥å£ä¸æ¶æ„ <a id='model-interface'></a>\n",
    "\n",
    "### Qlib Model Architecture / Qlibæ¨¡å‹æ¶æ„\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    Qlib Model Interface                     â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                             â”‚\n",
    "â”‚   Base Model Class                                         â”‚\n",
    "â”‚   â”œâ”€â”€ fit(dataset)          # Training / è®­ç»ƒ             â”‚\n",
    "â”‚   â”œâ”€â”€ predict(dataset)      # Prediction / é¢„æµ‹           â”‚\n",
    "â”‚   â””â”€â”€ finetune(dataset)     # Fine-tuning / å¾®è°ƒ         â”‚\n",
    "â”‚                                                             â”‚\n",
    "â”‚   Model Types / æ¨¡å‹ç±»å‹:                                  â”‚\n",
    "â”‚   â”œâ”€â”€ Tabular Models        # Traditional ML / ä¼ ç»Ÿæœºå™¨å­¦ä¹  â”‚\n",
    "â”‚   â”œâ”€â”€ Time Series Models    # Sequential / åºåˆ—æ¨¡å‹        â”‚\n",
    "â”‚   â””â”€â”€ Graph Models          # Relational / å…³ç³»æ¨¡å‹        â”‚\n",
    "â”‚                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model base class / è‡ªå®šä¹‰æ¨¡å‹åŸºç±»\n",
    "\n",
    "from qlib.model.base import Model\n",
    "from qlib.data.dataset.handler import DataHandlerLP\n",
    "\n",
    "class CustomModelBase(Model):\n",
    "    \"\"\"Custom base model class with enhanced features\n",
    "    å¸¦å¢å¼ºåŠŸèƒ½çš„è‡ªå®šä¹‰åŸºç¡€æ¨¡å‹ç±»\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.fitted = False\n",
    "        self.training_history = []\n",
    "        self.feature_importance = None\n",
    "    \n",
    "    def fit(self, dataset: DatasetH, **kwargs):\n",
    "        \"\"\"Enhanced fit method with logging\n",
    "        å¸¦æ—¥å¿—è®°å½•çš„å¢å¼ºè®­ç»ƒæ–¹æ³•\n",
    "        \"\"\"\n",
    "        print(f\"Starting training at {datetime.now()}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Get data\n",
    "        df_train, df_valid = self._prepare_data(dataset)\n",
    "        \n",
    "        # Actual training (to be implemented in subclasses)\n",
    "        self._fit_model(df_train, df_valid, **kwargs)\n",
    "        \n",
    "        # Record training time\n",
    "        training_time = time.time() - start_time\n",
    "        self.training_history.append({\n",
    "            'timestamp': datetime.now(),\n",
    "            'training_time': training_time,\n",
    "            'train_samples': len(df_train),\n",
    "            'valid_samples': len(df_valid) if df_valid is not None else 0\n",
    "        })\n",
    "        \n",
    "        self.fitted = True\n",
    "        print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "    \n",
    "    def predict(self, dataset: DatasetH, segment: str = \"test\"):\n",
    "        \"\"\"Enhanced predict method\n",
    "        å¢å¼ºé¢„æµ‹æ–¹æ³•\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Model must be fitted before prediction\")\n",
    "        \n",
    "        # Get test data\n",
    "        df_test = dataset.prepare(segment, col_set=['feature', 'label'])\n",
    "        \n",
    "        # Make predictions (to be implemented in subclasses)\n",
    "        predictions = self._predict_model(df_test)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def _prepare_data(self, dataset: DatasetH):\n",
    "        \"\"\"Prepare training and validation data\n",
    "        å‡†å¤‡è®­ç»ƒå’ŒéªŒè¯æ•°æ®\n",
    "        \"\"\"\n",
    "        df_train = dataset.prepare(\"train\", col_set=[\"feature\", \"label\"])\n",
    "        df_valid = dataset.prepare(\"valid\", col_set=[\"feature\", \"label\"]) if \"valid\" in dataset.segments else None\n",
    "        return df_train, df_valid\n",
    "    \n",
    "    def _fit_model(self, df_train, df_valid, **kwargs):\n",
    "        \"\"\"To be implemented by subclasses\n",
    "        ç”±å­ç±»å®ç°\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def _predict_model(self, df_test):\n",
    "        \"\"\"To be implemented by subclasses\n",
    "        ç”±å­ç±»å®ç°\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        \"\"\"Get feature importance if available\n",
    "        è·å–ç‰¹å¾é‡è¦æ€§ï¼ˆå¦‚æœå¯ç”¨ï¼‰\n",
    "        \"\"\"\n",
    "        return self.feature_importance\n",
    "\n",
    "print(\"âœ… Custom model base class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Preparation / æ•°æ®é›†å‡†å¤‡ <a id='dataset-prep'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare comprehensive dataset / å‡†å¤‡ç»¼åˆæ•°æ®é›†\n",
    "\n",
    "from qlib.contrib.data.handler import Alpha158\n",
    "\n",
    "# Create data handler / åˆ›å»ºæ•°æ®å¤„ç†å™¨\n",
    "handler_config = {\n",
    "    \"start_time\": TRAIN_START,\n",
    "    \"end_time\": TEST_END,\n",
    "    \"fit_start_time\": TRAIN_START,\n",
    "    \"fit_end_time\": TRAIN_END,\n",
    "    \"instruments\": MARKET,\n",
    "}\n",
    "\n",
    "# Initialize Alpha158 handler / åˆå§‹åŒ–Alpha158å¤„ç†å™¨\n",
    "handler = Alpha158(**handler_config)\n",
    "\n",
    "# Create dataset with segments / åˆ›å»ºå¸¦åˆ†æ®µçš„æ•°æ®é›†\n",
    "dataset_config = {\n",
    "    \"handler\": handler,\n",
    "    \"segments\": {\n",
    "        \"train\": (TRAIN_START, TRAIN_END),\n",
    "        \"valid\": (VALID_START, VALID_END),\n",
    "        \"test\": (TEST_START, TEST_END),\n",
    "    },\n",
    "}\n",
    "\n",
    "dataset = DatasetH(**dataset_config)\n",
    "\n",
    "# Display dataset information / æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯\n",
    "print(\"Dataset segments:\")\n",
    "for segment, (start, end) in dataset.segments.items():\n",
    "    df_segment = dataset.prepare(segment, col_set=['feature', 'label'], data_key=DataHandlerLP.DK_L)\n",
    "    print(f\"  {segment:10}: {start} to {end}, Shape: {df_segment.shape}\")\n",
    "\n",
    "# Sample data preview / æ•°æ®æ ·æœ¬é¢„è§ˆ\n",
    "df_sample = dataset.prepare(\"train\", col_set=['feature', 'label'], data_key=DataHandlerLP.DK_L).head()\n",
    "print(f\"\\nFeature columns: {df_sample.columns[:10].tolist()}...\")\n",
    "print(f\"Total features: {len(df_sample.columns) - 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Pipeline / è®­ç»ƒç®¡é“ <a id='training-pipeline'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive training pipeline / ç»¼åˆè®­ç»ƒç®¡é“\n",
    "\n",
    "class TrainingPipeline:\n",
    "    \"\"\"Complete training pipeline with experiment tracking\n",
    "    å¸¦å®éªŒè·Ÿè¸ªçš„å®Œæ•´è®­ç»ƒç®¡é“\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, experiment_name: str):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        \n",
    "    def add_model(self, name: str, model: Model):\n",
    "        \"\"\"Add a model to the pipeline\n",
    "        å‘ç®¡é“æ·»åŠ æ¨¡å‹\n",
    "        \"\"\"\n",
    "        self.models[name] = model\n",
    "        print(f\"Added model: {name}\")\n",
    "    \n",
    "    def train_all(self, dataset: DatasetH, save_models: bool = True):\n",
    "        \"\"\"Train all models in the pipeline\n",
    "        è®­ç»ƒç®¡é“ä¸­çš„æ‰€æœ‰æ¨¡å‹\n",
    "        \"\"\"\n",
    "        print(f\"\\nStarting training pipeline with {len(self.models)} models\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            print(f\"\\nTraining {name}...\")\n",
    "            \n",
    "            # Start experiment\n",
    "            with R.start(experiment_name=self.experiment_name):\n",
    "                # Train model\n",
    "                start_time = time.time()\n",
    "                model.fit(dataset)\n",
    "                training_time = time.time() - start_time\n",
    "                \n",
    "                # Make predictions\n",
    "                pred_train = model.predict(dataset, segment=\"train\")\n",
    "                pred_valid = model.predict(dataset, segment=\"valid\")\n",
    "                pred_test = model.predict(dataset, segment=\"test\")\n",
    "                \n",
    "                # Calculate metrics\n",
    "                metrics = self._calculate_metrics(dataset, pred_train, pred_valid, pred_test)\n",
    "                \n",
    "                # Store results\n",
    "                self.results[name] = {\n",
    "                    'model': model,\n",
    "                    'predictions': {\n",
    "                        'train': pred_train,\n",
    "                        'valid': pred_valid,\n",
    "                        'test': pred_test\n",
    "                    },\n",
    "                    'metrics': metrics,\n",
    "                    'training_time': training_time\n",
    "                }\n",
    "                \n",
    "                # Save model if requested\n",
    "                if save_models:\n",
    "                    R.save_objects(\n",
    "                        trained_model=model,\n",
    "                        predictions=pred_test,\n",
    "                        metrics=metrics\n",
    "                    )\n",
    "                \n",
    "                print(f\"  âœ… Training completed in {training_time:.2f}s\")\n",
    "                print(f\"  Test IC: {metrics['test_ic']:.4f}\")\n",
    "                print(f\"  Test Rank IC: {metrics['test_rank_ic']:.4f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Pipeline completed successfully!\")\n",
    "        return self.results\n",
    "    \n",
    "    def _calculate_metrics(self, dataset, pred_train, pred_valid, pred_test):\n",
    "        \"\"\"Calculate evaluation metrics\n",
    "        è®¡ç®—è¯„ä¼°æŒ‡æ ‡\n",
    "        \"\"\"\n",
    "        from scipy.stats import spearmanr\n",
    "        \n",
    "        metrics = {}\n",
    "        \n",
    "        # Get labels\n",
    "        label_train = dataset.prepare(\"train\", col_set=['label'], data_key=DataHandlerLP.DK_L)\n",
    "        label_valid = dataset.prepare(\"valid\", col_set=['label'], data_key=DataHandlerLP.DK_L)\n",
    "        label_test = dataset.prepare(\"test\", col_set=['label'], data_key=DataHandlerLP.DK_L)\n",
    "        \n",
    "        # Align predictions with labels\n",
    "        def calc_ic(pred, label):\n",
    "            df = pd.DataFrame({'pred': pred, 'label': label['label']}).dropna()\n",
    "            if len(df) > 0:\n",
    "                ic = df['pred'].corr(df['label'])\n",
    "                rank_ic = spearmanr(df['pred'], df['label'])[0]\n",
    "                return ic, rank_ic\n",
    "            return 0, 0\n",
    "        \n",
    "        # Calculate metrics for each segment\n",
    "        metrics['train_ic'], metrics['train_rank_ic'] = calc_ic(pred_train, label_train)\n",
    "        metrics['valid_ic'], metrics['valid_rank_ic'] = calc_ic(pred_valid, label_valid)\n",
    "        metrics['test_ic'], metrics['test_rank_ic'] = calc_ic(pred_test, label_test)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def compare_models(self):\n",
    "        \"\"\"Compare all trained models\n",
    "        æ¯”è¾ƒæ‰€æœ‰è®­ç»ƒè¿‡çš„æ¨¡å‹\n",
    "        \"\"\"\n",
    "        comparison_df = pd.DataFrame()\n",
    "        \n",
    "        for name, result in self.results.items():\n",
    "            metrics = result['metrics']\n",
    "            row = {\n",
    "                'Model': name,\n",
    "                'Train IC': metrics['train_ic'],\n",
    "                'Valid IC': metrics['valid_ic'],\n",
    "                'Test IC': metrics['test_ic'],\n",
    "                'Test Rank IC': metrics['test_rank_ic'],\n",
    "                'Training Time (s)': result['training_time']\n",
    "            }\n",
    "            comparison_df = pd.concat([comparison_df, pd.DataFrame([row])], ignore_index=True)\n",
    "        \n",
    "        return comparison_df.sort_values('Test IC', ascending=False)\n",
    "\n",
    "# Create pipeline / åˆ›å»ºç®¡é“\n",
    "pipeline = TrainingPipeline(experiment_name=EXP_NAME)\n",
    "print(\"âœ… Training pipeline created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Tree-Based Models / æ ‘æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LightGBM Models / LightGBMæ¨¡å‹ <a id='lightgbm'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM model configuration and training / LightGBMæ¨¡å‹é…ç½®å’Œè®­ç»ƒ\n",
    "\n",
    "from qlib.contrib.model.gbdt import LGBModel\n",
    "\n",
    "# Basic LightGBM configuration / åŸºç¡€LightGBMé…ç½®\n",
    "lgb_basic_config = {\n",
    "    \"loss\": \"mse\",\n",
    "    \"colsample_bytree\": 0.8879,\n",
    "    \"learning_rate\": 0.0421,\n",
    "    \"subsample\": 0.8789,\n",
    "    \"lambda_l1\": 205.6999,\n",
    "    \"lambda_l2\": 580.9768,\n",
    "    \"max_depth\": 8,\n",
    "    \"num_leaves\": 210,\n",
    "    \"num_threads\": 20,\n",
    "    \"verbosity\": -1,\n",
    "    \"early_stopping_rounds\": 50,\n",
    "}\n",
    "\n",
    "# Advanced LightGBM configuration / é«˜çº§LightGBMé…ç½®\n",
    "lgb_advanced_config = {\n",
    "    \"loss\": \"mse\",\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"num_boost_round\": 1000,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 256,\n",
    "    \"max_depth\": 10,\n",
    "    \"min_child_samples\": 20,\n",
    "    \"subsample\": 0.9,\n",
    "    \"subsample_freq\": 1,\n",
    "    \"colsample_bytree\": 0.9,\n",
    "    \"reg_alpha\": 100.0,\n",
    "    \"reg_lambda\": 100.0,\n",
    "    \"seed\": 42,\n",
    "    \"n_jobs\": -1,\n",
    "    \"silent\": True,\n",
    "    \"importance_type\": \"gain\",\n",
    "    \"early_stopping_rounds\": 100,\n",
    "}\n",
    "\n",
    "# Create LightGBM models / åˆ›å»ºLightGBMæ¨¡å‹\n",
    "lgb_basic = LGBModel(**lgb_basic_config)\n",
    "lgb_advanced = LGBModel(**lgb_advanced_config)\n",
    "\n",
    "# Add to pipeline / æ·»åŠ åˆ°ç®¡é“\n",
    "pipeline.add_model(\"LightGBM_Basic\", lgb_basic)\n",
    "pipeline.add_model(\"LightGBM_Advanced\", lgb_advanced)\n",
    "\n",
    "print(\"LightGBM configurations:\")\n",
    "print(f\"  Basic: {len(lgb_basic_config)} parameters\")\n",
    "print(f\"  Advanced: {len(lgb_advanced_config)} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom LightGBM with feature engineering / å¸¦ç‰¹å¾å·¥ç¨‹çš„è‡ªå®šä¹‰LightGBM\n",
    "\n",
    "class CustomLGBModel(LGBModel):\n",
    "    \"\"\"LightGBM with custom feature engineering\n",
    "    å¸¦è‡ªå®šä¹‰ç‰¹å¾å·¥ç¨‹çš„LightGBM\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, feature_engineer=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.feature_engineer = feature_engineer\n",
    "        self.feature_names = None\n",
    "    \n",
    "    def fit(self, dataset, **kwargs):\n",
    "        \"\"\"Fit with feature engineering\n",
    "        å¸¦ç‰¹å¾å·¥ç¨‹çš„è®­ç»ƒ\n",
    "        \"\"\"\n",
    "        # Apply feature engineering if provided\n",
    "        if self.feature_engineer:\n",
    "            dataset = self._apply_feature_engineering(dataset)\n",
    "        \n",
    "        # Call parent fit method\n",
    "        super().fit(dataset, **kwargs)\n",
    "        \n",
    "        # Extract feature importance\n",
    "        self._extract_feature_importance()\n",
    "    \n",
    "    def _apply_feature_engineering(self, dataset):\n",
    "        \"\"\"Apply custom feature engineering\n",
    "        åº”ç”¨è‡ªå®šä¹‰ç‰¹å¾å·¥ç¨‹\n",
    "        \"\"\"\n",
    "        # Example: Add rolling features\n",
    "        print(\"Applying feature engineering...\")\n",
    "        # Implementation would go here\n",
    "        return dataset\n",
    "    \n",
    "    def _extract_feature_importance(self):\n",
    "        \"\"\"Extract and store feature importance\n",
    "        æå–å¹¶å­˜å‚¨ç‰¹å¾é‡è¦æ€§\n",
    "        \"\"\"\n",
    "        if hasattr(self.model, 'feature_importance'):\n",
    "            importance = self.model.feature_importance(importance_type='gain')\n",
    "            if self.feature_names:\n",
    "                self.feature_importance = dict(zip(self.feature_names, importance))\n",
    "            else:\n",
    "                self.feature_importance = importance\n",
    "    \n",
    "    def get_top_features(self, n=20):\n",
    "        \"\"\"Get top n important features\n",
    "        è·å–å‰nä¸ªé‡è¦ç‰¹å¾\n",
    "        \"\"\"\n",
    "        if self.feature_importance and isinstance(self.feature_importance, dict):\n",
    "            sorted_features = sorted(self.feature_importance.items(), \n",
    "                                   key=lambda x: x[1], reverse=True)\n",
    "            return sorted_features[:n]\n",
    "        return None\n",
    "\n",
    "# Create custom LightGBM model / åˆ›å»ºè‡ªå®šä¹‰LightGBMæ¨¡å‹\n",
    "custom_lgb = CustomLGBModel(**lgb_basic_config)\n",
    "pipeline.add_model(\"LightGBM_Custom\", custom_lgb)\n",
    "\n",
    "print(\"âœ… Custom LightGBM model created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. XGBoost Models / XGBoostæ¨¡å‹ <a id='xgboost'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost model configuration / XGBoostæ¨¡å‹é…ç½®\n",
    "\n",
    "from qlib.contrib.model.xgboost import XGBModel\n",
    "\n",
    "# XGBoost configuration / XGBoosté…ç½®\n",
    "xgb_config = {\n",
    "    \"n_estimators\": 1000,\n",
    "    \"max_depth\": 8,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"subsample\": 0.9,\n",
    "    \"colsample_bytree\": 0.9,\n",
    "    \"reg_alpha\": 100,\n",
    "    \"reg_lambda\": 100,\n",
    "    \"min_child_weight\": 5,\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": \"rmse\",\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1,\n",
    "    \"early_stopping_rounds\": 50,\n",
    "    \"verbosity\": 0,\n",
    "}\n",
    "\n",
    "# GPU-accelerated XGBoost configuration / GPUåŠ é€Ÿçš„XGBoosté…ç½®\n",
    "xgb_gpu_config = {\n",
    "    **xgb_config,\n",
    "    \"tree_method\": \"gpu_hist\",  # Use GPU\n",
    "    \"gpu_id\": 0,\n",
    "    \"predictor\": \"gpu_predictor\",\n",
    "}\n",
    "\n",
    "# Create XGBoost models / åˆ›å»ºXGBoostæ¨¡å‹\n",
    "xgb_model = XGBModel(**xgb_config)\n",
    "# xgb_gpu_model = XGBModel(**xgb_gpu_config)  # Uncomment if GPU available\n",
    "\n",
    "# Add to pipeline / æ·»åŠ åˆ°ç®¡é“\n",
    "pipeline.add_model(\"XGBoost\", xgb_model)\n",
    "# pipeline.add_model(\"XGBoost_GPU\", xgb_gpu_model)\n",
    "\n",
    "print(f\"XGBoost model configured with {len(xgb_config)} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. CatBoost Models / CatBoostæ¨¡å‹ <a id='catboost'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost model configuration / CatBoostæ¨¡å‹é…ç½®\n",
    "\n",
    "from qlib.contrib.model.catboost import CatBoostModel\n",
    "\n",
    "# CatBoost configuration / CatBoosté…ç½®\n",
    "catboost_config = {\n",
    "    \"iterations\": 1000,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"depth\": 8,\n",
    "    \"l2_leaf_reg\": 100,\n",
    "    \"subsample\": 0.9,\n",
    "    \"colsample_bylevel\": 0.9,\n",
    "    \"random_seed\": 42,\n",
    "    \"loss_function\": \"RMSE\",\n",
    "    \"eval_metric\": \"RMSE\",\n",
    "    \"use_best_model\": True,\n",
    "    \"verbose\": False,\n",
    "    \"early_stopping_rounds\": 50,\n",
    "    \"thread_count\": -1,\n",
    "}\n",
    "\n",
    "# CatBoost with categorical features / å¸¦åˆ†ç±»ç‰¹å¾çš„CatBoost\n",
    "catboost_categorical_config = {\n",
    "    **catboost_config,\n",
    "    \"cat_features\": [],  # Specify categorical feature indices\n",
    "    \"one_hot_max_size\": 10,\n",
    "    \"has_time\": True,  # For time series\n",
    "}\n",
    "\n",
    "# Create CatBoost models / åˆ›å»ºCatBoostæ¨¡å‹\n",
    "catboost_model = CatBoostModel(**catboost_config)\n",
    "\n",
    "# Add to pipeline / æ·»åŠ åˆ°ç®¡é“\n",
    "pipeline.add_model(\"CatBoost\", catboost_model)\n",
    "\n",
    "print(f\"CatBoost model configured with {len(catboost_config)} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Tree Model Comparison / æ ‘æ¨¡å‹å¯¹æ¯” <a id='tree-comparison'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare tree-based models / æ¯”è¾ƒæ ‘æ¨¡å‹\n",
    "\n",
    "def compare_tree_models(models_dict, dataset, test_size=1000):\n",
    "    \"\"\"Compare different tree-based models\n",
    "    æ¯”è¾ƒä¸åŒçš„æ ‘æ¨¡å‹\n",
    "    \"\"\"\n",
    "    comparison_results = []\n",
    "    \n",
    "    # Get a small test sample for quick comparison\n",
    "    test_data = dataset.prepare(\"test\", col_set=['feature', 'label'], data_key=DataHandlerLP.DK_L).head(test_size)\n",
    "    \n",
    "    for name, model_config in models_dict.items():\n",
    "        print(f\"\\nEvaluating {name}...\")\n",
    "        \n",
    "        # Train model\n",
    "        start_time = time.time()\n",
    "        # model.fit(dataset)  # Would run actual training\n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        # Make predictions\n",
    "        start_time = time.time()\n",
    "        # predictions = model.predict(dataset, segment=\"test\")  # Would make actual predictions\n",
    "        predict_time = time.time() - start_time\n",
    "        \n",
    "        # Store results\n",
    "        comparison_results.append({\n",
    "            'Model': name,\n",
    "            'Parameters': len(model_config),\n",
    "            'Training Time': train_time,\n",
    "            'Prediction Time': predict_time,\n",
    "            'Memory Usage': 0,  # Would measure actual memory\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(comparison_results)\n",
    "\n",
    "# Define models for comparison / å®šä¹‰ç”¨äºæ¯”è¾ƒçš„æ¨¡å‹\n",
    "tree_models = {\n",
    "    'LightGBM': lgb_basic_config,\n",
    "    'XGBoost': xgb_config,\n",
    "    'CatBoost': catboost_config,\n",
    "}\n",
    "\n",
    "# Compare models / æ¯”è¾ƒæ¨¡å‹\n",
    "comparison_df = compare_tree_models(tree_models, dataset)\n",
    "print(\"\\nTree Model Comparison:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Visualize comparison / å¯è§†åŒ–æ¯”è¾ƒ\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Parameters comparison / å‚æ•°æ¯”è¾ƒ\n",
    "axes[0].bar(comparison_df['Model'], comparison_df['Parameters'])\n",
    "axes[0].set_title('Model Complexity (Parameter Count)')\n",
    "axes[0].set_xlabel('Model')\n",
    "axes[0].set_ylabel('Number of Parameters')\n",
    "\n",
    "# Feature importance comparison (placeholder) / ç‰¹å¾é‡è¦æ€§æ¯”è¾ƒï¼ˆå ä½ç¬¦ï¼‰\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': ['f1', 'f2', 'f3', 'f4', 'f5'],\n",
    "    'LightGBM': np.random.random(5),\n",
    "    'XGBoost': np.random.random(5),\n",
    "    'CatBoost': np.random.random(5),\n",
    "})\n",
    "feature_importance.set_index('Feature').plot(kind='bar', ax=axes[1])\n",
    "axes[1].set_title('Top 5 Feature Importance Comparison')\n",
    "axes[1].set_xlabel('Feature')\n",
    "axes[1].set_ylabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Deep Learning Models / æ·±åº¦å­¦ä¹ æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Neural Network Basics / ç¥ç»ç½‘ç»œåŸºç¡€ <a id='nn-basics'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network base configuration / ç¥ç»ç½‘ç»œåŸºç¡€é…ç½®\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Check GPU availability / æ£€æŸ¥GPUå¯ç”¨æ€§\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Base neural network configuration / åŸºç¡€ç¥ç»ç½‘ç»œé…ç½®\n",
    "nn_base_config = {\n",
    "    \"input_dim\": 158,  # Alpha158 features\n",
    "    \"hidden_dims\": [256, 128, 64],\n",
    "    \"output_dim\": 1,\n",
    "    \"dropout\": 0.3,\n",
    "    \"activation\": \"relu\",\n",
    "    \"batch_norm\": True,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 1024,\n",
    "    \"epochs\": 100,\n",
    "    \"early_stopping_patience\": 10,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss_fn\": \"mse\",\n",
    "    \"device\": device,\n",
    "}\n",
    "\n",
    "print(\"Neural network base configuration:\")\n",
    "for key, value in nn_base_config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. MLP for Stock Prediction / ç”¨äºè‚¡ç¥¨é¢„æµ‹çš„MLP <a id='mlp'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model implementation / MLPæ¨¡å‹å®ç°\n",
    "\n",
    "from qlib.contrib.model.pytorch_nn import DNNModel\n",
    "\n",
    "# MLP configuration / MLPé…ç½®\n",
    "mlp_config = {\n",
    "    \"batch_size\": 1024,\n",
    "    \"max_steps\": 8000,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"weight_decay\": 0.0001,\n",
    "    \"early_stopping_rounds\": 50,\n",
    "    \"eval_steps\": 20,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss\": \"mse\",\n",
    "    \"GPU\": 0 if torch.cuda.is_available() else None,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "# Advanced MLP with custom architecture / å¸¦è‡ªå®šä¹‰æ¶æ„çš„é«˜çº§MLP\n",
    "class CustomMLP(nn.Module):\n",
    "    \"\"\"Custom MLP architecture for stock prediction\n",
    "    ç”¨äºè‚¡ç¥¨é¢„æµ‹çš„è‡ªå®šä¹‰MLPæ¶æ„\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=158, hidden_dims=[512, 256, 128, 64], \n",
    "                 dropout=0.3, use_batch_norm=True):\n",
    "        super(CustomMLP, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            # Linear layer\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            \n",
    "            # Batch normalization\n",
    "            if use_batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            \n",
    "            # Activation\n",
    "            layers.append(nn.ReLU())\n",
    "            \n",
    "            # Dropout\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            \n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(prev_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Create MLP models / åˆ›å»ºMLPæ¨¡å‹\n",
    "mlp_model = DNNModel(**mlp_config)\n",
    "\n",
    "# Add to pipeline / æ·»åŠ åˆ°ç®¡é“\n",
    "pipeline.add_model(\"MLP\", mlp_model)\n",
    "\n",
    "print(\"âœ… MLP model created\")\n",
    "\n",
    "# Display architecture / æ˜¾ç¤ºæ¶æ„\n",
    "custom_mlp = CustomMLP()\n",
    "print(\"\\nCustom MLP Architecture:\")\n",
    "print(custom_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. LSTM and GRU Models / LSTMå’ŒGRUæ¨¡å‹ <a id='lstm-gru'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM and GRU models for time series / ç”¨äºæ—¶é—´åºåˆ—çš„LSTMå’ŒGRUæ¨¡å‹\n",
    "\n",
    "from qlib.contrib.model.pytorch_lstm import LSTMModel\n",
    "from qlib.contrib.model.pytorch_gru import GRUModel\n",
    "\n",
    "# LSTM configuration / LSTMé…ç½®\n",
    "lstm_config = {\n",
    "    \"d_feat\": 158,  # Input dimension\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.3,\n",
    "    \"batch_size\": 800,\n",
    "    \"early_stop\": 20,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"metric\": \"loss\",\n",
    "    \"loss\": \"mse\",\n",
    "    \"n_epochs\": 100,\n",
    "    \"GPU\": 0 if torch.cuda.is_available() else None,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "# GRU configuration / GRUé…ç½®\n",
    "gru_config = {\n",
    "    \"d_feat\": 158,\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.3,\n",
    "    \"batch_size\": 800,\n",
    "    \"early_stop\": 20,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"metric\": \"loss\",\n",
    "    \"loss\": \"mse\",\n",
    "    \"n_epochs\": 100,\n",
    "    \"GPU\": 0 if torch.cuda.is_available() else None,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "# Custom LSTM with attention mechanism / å¸¦æ³¨æ„åŠ›æœºåˆ¶çš„è‡ªå®šä¹‰LSTM\n",
    "class LSTMWithAttention(nn.Module):\n",
    "    \"\"\"LSTM with attention mechanism for better feature extraction\n",
    "    å¸¦æ³¨æ„åŠ›æœºåˆ¶çš„LSTMç”¨äºæ›´å¥½çš„ç‰¹å¾æå–\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout=0.3):\n",
    "        super(LSTMWithAttention, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim, hidden_dim, num_layers,\n",
    "            batch_first=True, dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Attention layers\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "        \n",
    "        self.output = nn.Linear(hidden_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # LSTM forward pass\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        attention_weights = torch.softmax(self.attention(lstm_out), dim=1)\n",
    "        context_vector = torch.sum(attention_weights * lstm_out, dim=1)\n",
    "        \n",
    "        # Output\n",
    "        output = self.output(context_vector)\n",
    "        return output\n",
    "\n",
    "# Create LSTM and GRU models / åˆ›å»ºLSTMå’ŒGRUæ¨¡å‹\n",
    "lstm_model = LSTMModel(**lstm_config)\n",
    "gru_model = GRUModel(**gru_config)\n",
    "\n",
    "# Add to pipeline / æ·»åŠ åˆ°ç®¡é“\n",
    "pipeline.add_model(\"LSTM\", lstm_model)\n",
    "pipeline.add_model(\"GRU\", gru_model)\n",
    "\n",
    "print(\"âœ… LSTM and GRU models created\")\n",
    "\n",
    "# Display custom architecture / æ˜¾ç¤ºè‡ªå®šä¹‰æ¶æ„\n",
    "lstm_attention = LSTMWithAttention(158, 128, 2)\n",
    "print(\"\\nLSTM with Attention Architecture:\")\n",
    "print(lstm_attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Transformer Models / Transformeræ¨¡å‹ <a id='transformer'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer model for stock prediction / ç”¨äºè‚¡ç¥¨é¢„æµ‹çš„Transformeræ¨¡å‹\n",
    "\n",
    "class StockTransformer(nn.Module):\n",
    "    \"\"\"Transformer model for stock prediction\n",
    "    ç”¨äºè‚¡ç¥¨é¢„æµ‹çš„Transformeræ¨¡å‹\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=158, d_model=128, nhead=8, \n",
    "                 num_layers=3, dropout=0.1):\n",
    "        super(StockTransformer, self).__init__()\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_projection = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.positional_encoding = PositionalEncoding(d_model, dropout)\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        \n",
    "        # Output layers\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input projection\n",
    "        x = self.input_projection(x)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        x = self.positional_encoding(x)\n",
    "        \n",
    "        # Transformer encoding\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        # Global pooling (take mean across sequence)\n",
    "        x = x.mean(dim=1)\n",
    "        \n",
    "        # Output\n",
    "        return self.output(x)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Positional encoding for transformer\n",
    "    Transformerçš„ä½ç½®ç¼–ç \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * \n",
    "                           (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# Create transformer model / åˆ›å»ºTransformeræ¨¡å‹\n",
    "transformer_model = StockTransformer()\n",
    "print(\"âœ… Transformer model created\")\n",
    "print(f\"\\nModel parameters: {sum(p.numel() for p in transformer_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Model Optimization / æ¨¡å‹ä¼˜åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Hyperparameter Tuning / è¶…å‚æ•°è°ƒä¼˜ <a id='hyperparameter'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning with Optuna / ä½¿ç”¨Optunaè¿›è¡Œè¶…å‚æ•°è°ƒä¼˜\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "class HyperparameterTuner:\n",
    "    \"\"\"Automated hyperparameter tuning framework\n",
    "    è‡ªåŠ¨è¶…å‚æ•°è°ƒä¼˜æ¡†æ¶\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_class, dataset, n_trials=50):\n",
    "        self.model_class = model_class\n",
    "        self.dataset = dataset\n",
    "        self.n_trials = n_trials\n",
    "        self.best_params = None\n",
    "        self.best_score = None\n",
    "    \n",
    "    def objective_lgb(self, trial):\n",
    "        \"\"\"Objective function for LightGBM\n",
    "        LightGBMçš„ç›®æ ‡å‡½æ•°\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 100.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 100.0, log=True),\n",
    "            'loss': 'mse',\n",
    "            'early_stopping_rounds': 50,\n",
    "            'num_threads': 20,\n",
    "        }\n",
    "        \n",
    "        # Train model with suggested parameters\n",
    "        model = LGBModel(**params)\n",
    "        model.fit(self.dataset)\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        pred_valid = model.predict(self.dataset, segment=\"valid\")\n",
    "        label_valid = self.dataset.prepare(\"valid\", col_set=['label'], data_key=DataHandlerLP.DK_L)\n",
    "        \n",
    "        # Calculate IC as objective\n",
    "        df = pd.DataFrame({'pred': pred_valid, 'label': label_valid['label']}).dropna()\n",
    "        ic = df['pred'].corr(df['label'])\n",
    "        \n",
    "        return ic  # Optuna maximizes by default\n",
    "    \n",
    "    def objective_nn(self, trial):\n",
    "        \"\"\"Objective function for neural networks\n",
    "        ç¥ç»ç½‘ç»œçš„ç›®æ ‡å‡½æ•°\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            'hidden_size': trial.suggest_categorical('hidden_size', [64, 128, 256, 512]),\n",
    "            'num_layers': trial.suggest_int('num_layers', 1, 4),\n",
    "            'dropout': trial.suggest_float('dropout', 0.1, 0.5),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True),\n",
    "            'batch_size': trial.suggest_categorical('batch_size', [256, 512, 1024, 2048]),\n",
    "            'weight_decay': trial.suggest_float('weight_decay', 1e-8, 1e-3, log=True),\n",
    "        }\n",
    "        \n",
    "        # Train and evaluate model\n",
    "        # ... (implementation)\n",
    "        \n",
    "        return 0  # Placeholder\n",
    "    \n",
    "    def tune(self, model_type='lgb'):\n",
    "        \"\"\"Run hyperparameter tuning\n",
    "        è¿è¡Œè¶…å‚æ•°è°ƒä¼˜\n",
    "        \"\"\"\n",
    "        print(f\"Starting hyperparameter tuning for {model_type}...\")\n",
    "        \n",
    "        # Select objective function\n",
    "        if model_type == 'lgb':\n",
    "            objective = self.objective_lgb\n",
    "        elif model_type == 'nn':\n",
    "            objective = self.objective_nn\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "        \n",
    "        # Create study\n",
    "        study = optuna.create_study(\n",
    "            direction='maximize',\n",
    "            sampler=TPESampler(seed=42)\n",
    "        )\n",
    "        \n",
    "        # Optimize\n",
    "        study.optimize(objective, n_trials=self.n_trials)\n",
    "        \n",
    "        # Store best parameters\n",
    "        self.best_params = study.best_params\n",
    "        self.best_score = study.best_value\n",
    "        \n",
    "        print(f\"\\nBest score: {self.best_score:.4f}\")\n",
    "        print(f\"Best parameters: {self.best_params}\")\n",
    "        \n",
    "        return study\n",
    "\n",
    "# Example tuning (would run actual tuning)\n",
    "print(\"Hyperparameter tuning framework ready\")\n",
    "print(\"\\nExample parameter search space for LightGBM:\")\n",
    "print(\"  num_leaves: [20, 300]\")\n",
    "print(\"  learning_rate: [0.01, 0.3]\")\n",
    "print(\"  max_depth: [3, 12]\")\n",
    "print(\"  subsample: [0.5, 1.0]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Feature Selection / ç‰¹å¾é€‰æ‹© <a id='feature-selection'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection methods / ç‰¹å¾é€‰æ‹©æ–¹æ³•\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, f_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "class FeatureSelector:\n",
    "    \"\"\"Comprehensive feature selection framework\n",
    "    ç»¼åˆç‰¹å¾é€‰æ‹©æ¡†æ¶\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.selected_features = {}\n",
    "        self.feature_scores = {}\n",
    "    \n",
    "    def select_by_importance(self, model, top_k=50):\n",
    "        \"\"\"Select features by model importance\n",
    "        é€šè¿‡æ¨¡å‹é‡è¦æ€§é€‰æ‹©ç‰¹å¾\n",
    "        \"\"\"\n",
    "        # Train model\n",
    "        model.fit(self.dataset)\n",
    "        \n",
    "        # Get feature importance\n",
    "        if hasattr(model, 'feature_importance'):\n",
    "            importance = model.feature_importance()\n",
    "            \n",
    "            # Sort and select top features\n",
    "            sorted_idx = np.argsort(importance)[::-1]\n",
    "            selected_idx = sorted_idx[:top_k]\n",
    "            \n",
    "            # Get feature names\n",
    "            train_data = self.dataset.prepare(\"train\", col_set=['feature'])\n",
    "            feature_names = train_data.columns.tolist()\n",
    "            \n",
    "            self.selected_features['importance'] = [feature_names[i] for i in selected_idx]\n",
    "            self.feature_scores['importance'] = importance[selected_idx]\n",
    "            \n",
    "            return self.selected_features['importance']\n",
    "    \n",
    "    def select_by_mutual_info(self, top_k=50):\n",
    "        \"\"\"Select features by mutual information\n",
    "        é€šè¿‡äº’ä¿¡æ¯é€‰æ‹©ç‰¹å¾\n",
    "        \"\"\"\n",
    "        # Get data\n",
    "        train_data = self.dataset.prepare(\"train\", col_set=['feature', 'label'])\n",
    "        X = train_data.iloc[:, :-1]\n",
    "        y = train_data.iloc[:, -1]\n",
    "        \n",
    "        # Calculate mutual information\n",
    "        selector = SelectKBest(mutual_info_regression, k=top_k)\n",
    "        selector.fit(X, y)\n",
    "        \n",
    "        # Get selected features\n",
    "        selected_mask = selector.get_support()\n",
    "        self.selected_features['mutual_info'] = X.columns[selected_mask].tolist()\n",
    "        self.feature_scores['mutual_info'] = selector.scores_[selected_mask]\n",
    "        \n",
    "        return self.selected_features['mutual_info']\n",
    "    \n",
    "    def select_by_correlation(self, threshold=0.95):\n",
    "        \"\"\"Remove highly correlated features\n",
    "        ç§»é™¤é«˜åº¦ç›¸å…³çš„ç‰¹å¾\n",
    "        \"\"\"\n",
    "        # Get data\n",
    "        train_data = self.dataset.prepare(\"train\", col_set=['feature'])\n",
    "        \n",
    "        # Calculate correlation matrix\n",
    "        corr_matrix = train_data.corr().abs()\n",
    "        \n",
    "        # Find features to remove\n",
    "        upper_tri = corr_matrix.where(\n",
    "            np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "        )\n",
    "        \n",
    "        to_drop = [column for column in upper_tri.columns \n",
    "                  if any(upper_tri[column] > threshold)]\n",
    "        \n",
    "        # Keep features\n",
    "        self.selected_features['correlation'] = [\n",
    "            col for col in train_data.columns if col not in to_drop\n",
    "        ]\n",
    "        \n",
    "        return self.selected_features['correlation']\n",
    "    \n",
    "    def select_by_recursive_elimination(self, estimator=None, n_features=50):\n",
    "        \"\"\"Recursive feature elimination\n",
    "        é€’å½’ç‰¹å¾æ¶ˆé™¤\n",
    "        \"\"\"\n",
    "        from sklearn.feature_selection import RFE\n",
    "        \n",
    "        # Get data\n",
    "        train_data = self.dataset.prepare(\"train\", col_set=['feature', 'label'])\n",
    "        X = train_data.iloc[:, :-1]\n",
    "        y = train_data.iloc[:, -1]\n",
    "        \n",
    "        # Use default estimator if not provided\n",
    "        if estimator is None:\n",
    "            estimator = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "        \n",
    "        # RFE\n",
    "        selector = RFE(estimator, n_features_to_select=n_features)\n",
    "        selector.fit(X, y)\n",
    "        \n",
    "        # Get selected features\n",
    "        self.selected_features['rfe'] = X.columns[selector.support_].tolist()\n",
    "        \n",
    "        return self.selected_features['rfe']\n",
    "    \n",
    "    def combine_selections(self, methods=['importance', 'mutual_info'], min_votes=2):\n",
    "        \"\"\"Combine multiple feature selection methods\n",
    "        ç»„åˆå¤šç§ç‰¹å¾é€‰æ‹©æ–¹æ³•\n",
    "        \"\"\"\n",
    "        from collections import Counter\n",
    "        \n",
    "        # Count votes for each feature\n",
    "        all_features = []\n",
    "        for method in methods:\n",
    "            if method in self.selected_features:\n",
    "                all_features.extend(self.selected_features[method])\n",
    "        \n",
    "        feature_votes = Counter(all_features)\n",
    "        \n",
    "        # Select features with enough votes\n",
    "        combined_features = [\n",
    "            feature for feature, votes in feature_votes.items() \n",
    "            if votes >= min_votes\n",
    "        ]\n",
    "        \n",
    "        return combined_features\n",
    "\n",
    "# Example usage\n",
    "print(\"Feature selection framework ready\")\n",
    "print(\"\\nAvailable methods:\")\n",
    "print(\"  1. Model importance-based selection\")\n",
    "print(\"  2. Mutual information selection\")\n",
    "print(\"  3. Correlation-based removal\")\n",
    "print(\"  4. Recursive feature elimination\")\n",
    "print(\"  5. Ensemble voting combination\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Ensemble Methods / é›†æˆæ–¹æ³• <a id='ensemble'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble methods for model combination / æ¨¡å‹ç»„åˆçš„é›†æˆæ–¹æ³•\n",
    "\n",
    "class EnsembleModel:\n",
    "    \"\"\"Ensemble model framework\n",
    "    é›†æˆæ¨¡å‹æ¡†æ¶\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, models, weights=None, method='average'):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - models: List of trained models\n",
    "        - weights: Model weights for weighted average\n",
    "        - method: 'average', 'weighted', 'stacking', 'blending'\n",
    "        \"\"\"\n",
    "        self.models = models\n",
    "        self.weights = weights or [1/len(models)] * len(models)\n",
    "        self.method = method\n",
    "        self.meta_model = None\n",
    "    \n",
    "    def predict_average(self, dataset, segment=\"test\"):\n",
    "        \"\"\"Simple average ensemble\n",
    "        ç®€å•å¹³å‡é›†æˆ\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        \n",
    "        for model in self.models:\n",
    "            pred = model.predict(dataset, segment)\n",
    "            predictions.append(pred)\n",
    "        \n",
    "        # Stack predictions and take mean\n",
    "        pred_matrix = np.column_stack(predictions)\n",
    "        ensemble_pred = pred_matrix.mean(axis=1)\n",
    "        \n",
    "        return ensemble_pred\n",
    "    \n",
    "    def predict_weighted(self, dataset, segment=\"test\"):\n",
    "        \"\"\"Weighted average ensemble\n",
    "        åŠ æƒå¹³å‡é›†æˆ\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        \n",
    "        for model, weight in zip(self.models, self.weights):\n",
    "            pred = model.predict(dataset, segment)\n",
    "            predictions.append(pred * weight)\n",
    "        \n",
    "        # Sum weighted predictions\n",
    "        ensemble_pred = np.sum(predictions, axis=0)\n",
    "        \n",
    "        return ensemble_pred\n",
    "    \n",
    "    def train_stacking(self, dataset):\n",
    "        \"\"\"Train stacking ensemble\n",
    "        è®­ç»ƒå †å é›†æˆ\n",
    "        \"\"\"\n",
    "        # Get base model predictions on validation set\n",
    "        valid_predictions = []\n",
    "        \n",
    "        for model in self.models:\n",
    "            pred = model.predict(dataset, segment=\"valid\")\n",
    "            valid_predictions.append(pred)\n",
    "        \n",
    "        # Stack predictions as features\n",
    "        X_meta = np.column_stack(valid_predictions)\n",
    "        \n",
    "        # Get validation labels\n",
    "        y_valid = dataset.prepare(\"valid\", col_set=['label'])['label'].values\n",
    "        \n",
    "        # Train meta-model\n",
    "        from sklearn.linear_model import Ridge\n",
    "        self.meta_model = Ridge(alpha=1.0)\n",
    "        self.meta_model.fit(X_meta, y_valid)\n",
    "        \n",
    "        print(\"Stacking meta-model trained\")\n",
    "    \n",
    "    def predict_stacking(self, dataset, segment=\"test\"):\n",
    "        \"\"\"Predict with stacking ensemble\n",
    "        ä½¿ç”¨å †å é›†æˆé¢„æµ‹\n",
    "        \"\"\"\n",
    "        if self.meta_model is None:\n",
    "            raise ValueError(\"Must train stacking model first\")\n",
    "        \n",
    "        # Get base model predictions\n",
    "        test_predictions = []\n",
    "        \n",
    "        for model in self.models:\n",
    "            pred = model.predict(dataset, segment)\n",
    "            test_predictions.append(pred)\n",
    "        \n",
    "        # Stack predictions\n",
    "        X_meta = np.column_stack(test_predictions)\n",
    "        \n",
    "        # Meta-model prediction\n",
    "        ensemble_pred = self.meta_model.predict(X_meta)\n",
    "        \n",
    "        return ensemble_pred\n",
    "    \n",
    "    def optimize_weights(self, dataset):\n",
    "        \"\"\"Optimize ensemble weights\n",
    "        ä¼˜åŒ–é›†æˆæƒé‡\n",
    "        \"\"\"\n",
    "        from scipy.optimize import minimize\n",
    "        \n",
    "        # Get validation predictions\n",
    "        valid_predictions = []\n",
    "        for model in self.models:\n",
    "            pred = model.predict(dataset, segment=\"valid\")\n",
    "            valid_predictions.append(pred)\n",
    "        \n",
    "        pred_matrix = np.column_stack(valid_predictions)\n",
    "        \n",
    "        # Get validation labels\n",
    "        y_valid = dataset.prepare(\"valid\", col_set=['label'])['label'].values\n",
    "        \n",
    "        # Objective function\n",
    "        def objective(weights):\n",
    "            weighted_pred = np.dot(pred_matrix, weights)\n",
    "            mse = np.mean((weighted_pred - y_valid) ** 2)\n",
    "            return mse\n",
    "        \n",
    "        # Constraints: weights sum to 1, all positive\n",
    "        constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "        bounds = [(0, 1)] * len(self.models)\n",
    "        \n",
    "        # Initial weights\n",
    "        init_weights = [1/len(self.models)] * len(self.models)\n",
    "        \n",
    "        # Optimize\n",
    "        result = minimize(objective, init_weights, method='SLSQP',\n",
    "                        bounds=bounds, constraints=constraints)\n",
    "        \n",
    "        self.weights = result.x\n",
    "        print(f\"Optimized weights: {self.weights}\")\n",
    "        \n",
    "        return self.weights\n",
    "\n",
    "print(\"Ensemble framework ready\")\n",
    "print(\"\\nAvailable ensemble methods:\")\n",
    "print(\"  1. Simple averaging\")\n",
    "print(\"  2. Weighted averaging\")\n",
    "print(\"  3. Stacking with meta-learner\")\n",
    "print(\"  4. Weight optimization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Production Deployment / ç”Ÿäº§éƒ¨ç½²"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Model Persistence / æ¨¡å‹æŒä¹…åŒ– <a id='persistence'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model persistence and versioning / æ¨¡å‹æŒä¹…åŒ–å’Œç‰ˆæœ¬æ§åˆ¶\n",
    "\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "\n",
    "class ModelManager:\n",
    "    \"\"\"Model management system for production\n",
    "    ç”Ÿäº§ç¯å¢ƒçš„æ¨¡å‹ç®¡ç†ç³»ç»Ÿ\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_dir=\"./models\"):\n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.base_dir.mkdir(exist_ok=True)\n",
    "        self.model_registry = {}\n",
    "    \n",
    "    def save_model(self, model, name, version=None, metadata=None):\n",
    "        \"\"\"Save model with versioning\n",
    "        å¸¦ç‰ˆæœ¬æ§åˆ¶çš„æ¨¡å‹ä¿å­˜\n",
    "        \"\"\"\n",
    "        # Generate version if not provided\n",
    "        if version is None:\n",
    "            version = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Create model directory\n",
    "        model_dir = self.base_dir / name / version\n",
    "        model_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save model\n",
    "        model_path = model_dir / \"model.pkl\"\n",
    "        joblib.dump(model, model_path)\n",
    "        \n",
    "        # Save metadata\n",
    "        if metadata is None:\n",
    "            metadata = {}\n",
    "        \n",
    "        metadata.update({\n",
    "            'name': name,\n",
    "            'version': version,\n",
    "            'saved_at': datetime.now().isoformat(),\n",
    "            'model_class': model.__class__.__name__,\n",
    "            'file_hash': self._calculate_hash(model_path)\n",
    "        })\n",
    "        \n",
    "        metadata_path = model_dir / \"metadata.json\"\n",
    "        with open(metadata_path, 'w') as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "        \n",
    "        # Update registry\n",
    "        self.model_registry[f\"{name}:{version}\"] = {\n",
    "            'path': model_path,\n",
    "            'metadata': metadata\n",
    "        }\n",
    "        \n",
    "        print(f\"Model saved: {name}:{version}\")\n",
    "        return model_path\n",
    "    \n",
    "    def load_model(self, name, version=\"latest\"):\n",
    "        \"\"\"Load model by name and version\n",
    "        æŒ‰åç§°å’Œç‰ˆæœ¬åŠ è½½æ¨¡å‹\n",
    "        \"\"\"\n",
    "        # Find model version\n",
    "        if version == \"latest\":\n",
    "            model_versions = list((self.base_dir / name).glob(\"*\"))\n",
    "            if not model_versions:\n",
    "                raise ValueError(f\"No versions found for model {name}\")\n",
    "            version = sorted(model_versions)[-1].name\n",
    "        \n",
    "        # Load model\n",
    "        model_path = self.base_dir / name / version / \"model.pkl\"\n",
    "        if not model_path.exists():\n",
    "            raise FileNotFoundError(f\"Model not found: {model_path}\")\n",
    "        \n",
    "        model = joblib.load(model_path)\n",
    "        \n",
    "        # Load metadata\n",
    "        metadata_path = self.base_dir / name / version / \"metadata.json\"\n",
    "        if metadata_path.exists():\n",
    "            with open(metadata_path, 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "        else:\n",
    "            metadata = {}\n",
    "        \n",
    "        print(f\"Model loaded: {name}:{version}\")\n",
    "        return model, metadata\n",
    "    \n",
    "    def list_models(self):\n",
    "        \"\"\"List all available models\n",
    "        åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹\n",
    "        \"\"\"\n",
    "        models = []\n",
    "        \n",
    "        for model_dir in self.base_dir.glob(\"*\"):\n",
    "            if model_dir.is_dir():\n",
    "                for version_dir in model_dir.glob(\"*\"):\n",
    "                    if version_dir.is_dir():\n",
    "                        models.append({\n",
    "                            'name': model_dir.name,\n",
    "                            'version': version_dir.name,\n",
    "                            'path': version_dir\n",
    "                        })\n",
    "        \n",
    "        return pd.DataFrame(models)\n",
    "    \n",
    "    def _calculate_hash(self, file_path):\n",
    "        \"\"\"Calculate file hash for integrity check\n",
    "        è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼ä»¥è¿›è¡Œå®Œæ•´æ€§æ£€æŸ¥\n",
    "        \"\"\"\n",
    "        hash_md5 = hashlib.md5()\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "                hash_md5.update(chunk)\n",
    "        return hash_md5.hexdigest()\n",
    "\n",
    "# Example usage\n",
    "model_manager = ModelManager()\n",
    "print(\"Model manager initialized\")\n",
    "print(f\"Model directory: {model_manager.base_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. Model Monitoring / æ¨¡å‹ç›‘æ§ <a id='monitoring'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model monitoring system / æ¨¡å‹ç›‘æ§ç³»ç»Ÿ\n",
    "\n",
    "class ModelMonitor:\n",
    "    \"\"\"Production model monitoring\n",
    "    ç”Ÿäº§æ¨¡å‹ç›‘æ§\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "        self.metrics_history = []\n",
    "        self.alerts = []\n",
    "        self.thresholds = {\n",
    "            'ic_min': 0.01,\n",
    "            'prediction_std_max': 0.1,\n",
    "            'null_rate_max': 0.05\n",
    "        }\n",
    "    \n",
    "    def monitor_prediction_quality(self, predictions, labels=None):\n",
    "        \"\"\"Monitor prediction quality metrics\n",
    "        ç›‘æ§é¢„æµ‹è´¨é‡æŒ‡æ ‡\n",
    "        \"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # Basic statistics\n",
    "        metrics['mean'] = np.mean(predictions)\n",
    "        metrics['std'] = np.std(predictions)\n",
    "        metrics['min'] = np.min(predictions)\n",
    "        metrics['max'] = np.max(predictions)\n",
    "        metrics['null_rate'] = np.isnan(predictions).mean()\n",
    "        \n",
    "        # IC if labels available\n",
    "        if labels is not None:\n",
    "            valid_idx = ~(np.isnan(predictions) | np.isnan(labels))\n",
    "            if valid_idx.sum() > 0:\n",
    "                metrics['ic'] = np.corrcoef(\n",
    "                    predictions[valid_idx], \n",
    "                    labels[valid_idx]\n",
    "                )[0, 1]\n",
    "        \n",
    "        # Check alerts\n",
    "        self._check_alerts(metrics)\n",
    "        \n",
    "        # Store metrics\n",
    "        metrics['timestamp'] = datetime.now()\n",
    "        self.metrics_history.append(metrics)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def _check_alerts(self, metrics):\n",
    "        \"\"\"Check if any alerts should be triggered\n",
    "        æ£€æŸ¥æ˜¯å¦åº”è§¦å‘ä»»ä½•è­¦æŠ¥\n",
    "        \"\"\"\n",
    "        # IC degradation\n",
    "        if 'ic' in metrics and metrics['ic'] < self.thresholds['ic_min']:\n",
    "            self.alerts.append({\n",
    "                'type': 'IC_DEGRADATION',\n",
    "                'message': f\"IC {metrics['ic']:.4f} below threshold {self.thresholds['ic_min']}\",\n",
    "                'timestamp': datetime.now()\n",
    "            })\n",
    "        \n",
    "        # High null rate\n",
    "        if metrics['null_rate'] > self.thresholds['null_rate_max']:\n",
    "            self.alerts.append({\n",
    "                'type': 'HIGH_NULL_RATE',\n",
    "                'message': f\"Null rate {metrics['null_rate']:.2%} exceeds threshold\",\n",
    "                'timestamp': datetime.now()\n",
    "            })\n",
    "    \n",
    "    def get_monitoring_report(self):\n",
    "        \"\"\"Generate monitoring report\n",
    "        ç”Ÿæˆç›‘æ§æŠ¥å‘Š\n",
    "        \"\"\"\n",
    "        if not self.metrics_history:\n",
    "            return \"No metrics available\"\n",
    "        \n",
    "        report = f\"\\nModel Monitoring Report: {self.model_name}\\n\"\n",
    "        report += \"=\"*50 + \"\\n\"\n",
    "        \n",
    "        # Recent metrics\n",
    "        recent = self.metrics_history[-1]\n",
    "        report += \"\\nRecent Metrics:\\n\"\n",
    "        for key, value in recent.items():\n",
    "            if key != 'timestamp':\n",
    "                report += f\"  {key}: {value:.4f}\\n\"\n",
    "        \n",
    "        # Alerts\n",
    "        if self.alerts:\n",
    "            report += f\"\\nAlerts ({len(self.alerts)}):\\n\"\n",
    "            for alert in self.alerts[-5:]:  # Last 5 alerts\n",
    "                report += f\"  [{alert['type']}] {alert['message']}\\n\"\n",
    "        \n",
    "        return report\n",
    "\n",
    "# Example monitoring\n",
    "monitor = ModelMonitor(\"LightGBM_Production\")\n",
    "\n",
    "# Simulate monitoring\n",
    "for i in range(5):\n",
    "    predictions = np.random.randn(1000) * 0.01\n",
    "    labels = np.random.randn(1000) * 0.01\n",
    "    metrics = monitor.monitor_prediction_quality(predictions, labels)\n",
    "\n",
    "print(monitor.get_monitoring_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary / æ€»ç»“\n",
    "\n",
    "### What we covered / æœ¬ç« å†…å®¹\n",
    "\n",
    "#### Part 1: Model Fundamentals / æ¨¡å‹åŸºç¡€\n",
    "- Model interface and architecture / æ¨¡å‹æ¥å£ä¸æ¶æ„\n",
    "- Dataset preparation / æ•°æ®é›†å‡†å¤‡\n",
    "- Training pipeline / è®­ç»ƒç®¡é“\n",
    "\n",
    "#### Part 2: Tree-Based Models / æ ‘æ¨¡å‹\n",
    "- **LightGBM**: Fast and efficient gradient boosting / å¿«é€Ÿé«˜æ•ˆçš„æ¢¯åº¦æå‡\n",
    "- **XGBoost**: Scalable gradient boosting / å¯æ‰©å±•çš„æ¢¯åº¦æå‡\n",
    "- **CatBoost**: Handling categorical features / å¤„ç†åˆ†ç±»ç‰¹å¾\n",
    "\n",
    "#### Part 3: Deep Learning Models / æ·±åº¦å­¦ä¹ æ¨¡å‹\n",
    "- **MLP**: Multi-layer perceptrons / å¤šå±‚æ„ŸçŸ¥å™¨\n",
    "- **LSTM/GRU**: Sequential models / åºåˆ—æ¨¡å‹\n",
    "- **Transformer**: Attention-based models / åŸºäºæ³¨æ„åŠ›çš„æ¨¡å‹\n",
    "- **GNN**: Graph neural networks / å›¾ç¥ç»ç½‘ç»œ\n",
    "\n",
    "#### Part 4: Model Optimization / æ¨¡å‹ä¼˜åŒ–\n",
    "- **Hyperparameter Tuning**: Optuna optimization / Optunaä¼˜åŒ–\n",
    "- **Feature Selection**: Multiple methods / å¤šç§æ–¹æ³•\n",
    "- **Ensemble Methods**: Model combination / æ¨¡å‹ç»„åˆ\n",
    "- **Cross-Validation**: Robust evaluation / ç¨³å¥è¯„ä¼°\n",
    "\n",
    "#### Part 5: Production Deployment / ç”Ÿäº§éƒ¨ç½²\n",
    "- **Model Persistence**: Versioning and storage / ç‰ˆæœ¬æ§åˆ¶å’Œå­˜å‚¨\n",
    "- **Online Learning**: Incremental updates / å¢é‡æ›´æ–°\n",
    "- **Model Monitoring**: Performance tracking / æ€§èƒ½è·Ÿè¸ª\n",
    "- **Best Practices**: Production guidelines / ç”Ÿäº§æŒ‡å—\n",
    "\n",
    "### Key Takeaways / å…³é”®è¦ç‚¹\n",
    "\n",
    "1. **Model Selection**: Choose models based on data characteristics / æ ¹æ®æ•°æ®ç‰¹å¾é€‰æ‹©æ¨¡å‹\n",
    "2. **Feature Engineering**: Critical for performance / å¯¹æ€§èƒ½è‡³å…³é‡è¦\n",
    "3. **Hyperparameter Tuning**: Systematic optimization / ç³»ç»ŸåŒ–ä¼˜åŒ–\n",
    "4. **Ensemble Methods**: Often improve performance / é€šå¸¸èƒ½æé«˜æ€§èƒ½\n",
    "5. **Production Readiness**: Monitor and maintain models / ç›‘æ§å’Œç»´æŠ¤æ¨¡å‹\n",
    "\n",
    "### Next Steps / ä¸‹ä¸€æ­¥\n",
    "\n",
    "Continue with **[04_evaluation_module.ipynb](./04_evaluation_module.ipynb)** to learn about:\n",
    "- Backtesting strategies / å›æµ‹ç­–ç•¥\n",
    "- Performance evaluation / æ€§èƒ½è¯„ä¼°\n",
    "- Risk analysis / é£é™©åˆ†æ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}